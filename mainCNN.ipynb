{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from skimage import exposure, io\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda\n",
    "import tidalUtl.Scheduler as sch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet \n",
    "\n",
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV cross entropy 0.102：CV accuracy 0.802<br>\n",
    "__ver2__<br>\n",
    "IAASharpen：CV cross entropy 0.0903：CV accuracy 0.823<br>\n",
    "__ver3__<br>\n",
    "EPOCH75,BATCH1024：CV cross entropy 0.0549：CV accuracy 0.909<br>\n",
    "__ver4__<br>\n",
    "TTA：CV cross entropy ：CV accuracy <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/CIFAR10/cifar-10-python/cifar-10-batches-py\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/CIFAR10/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/Pytorch/\"\n",
    "SAVEOOF = OUTPUT + \"/OOF/Pytorch/\"\n",
    "SAVEPLOT = OUTPUT + \"/plot_history/\"\n",
    "\n",
    "#ARCH = EfficientNet.from_pretrained('efficientnet-b1') \n",
    "\n",
    "# RUN\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 75\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "VALID_BATCH_SIZE = 512\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 50\n",
    "EARLY_STOP = False\n",
    "AUGMENT_PRB = 1\n",
    "IMG_VSL_FLG_TRAIN = True\n",
    "IMG_VSL_FLG_VALID = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "metaData = unpickle(INPUT + '/batches.meta')\n",
    "batch1 = unpickle(INPUT + '/data_batch_1')\n",
    "batch2 = unpickle(INPUT + '/data_batch_2')\n",
    "batch3 = unpickle(INPUT + '/data_batch_3')\n",
    "batch4 = unpickle(INPUT + '/data_batch_4')\n",
    "batch5 = unpickle(INPUT + '/data_batch_5')\n",
    "testBatch = unpickle(INPUT + '/test_batch')\n",
    "\n",
    "#trainは分割されていたのを一つに結合(この時点ではまだseries)\n",
    "trainFeature = np.concatenate([batch1[b'data'], \n",
    "                               batch2[b'data'],\n",
    "                               batch3[b'data'],\n",
    "                               batch4[b'data'],\n",
    "                               batch5[b'data'],])\n",
    "testFeature = testBatch[b'data']\n",
    "\n",
    "trainTarget = np.concatenate([batch1[b'labels'], \n",
    "                               batch2[b'labels'],\n",
    "                               batch3[b'labels'],\n",
    "                               batch4[b'labels'],\n",
    "                               batch5[b'labels'],])\n",
    "testTarget = np.array(testBatch[b'labels'])\n",
    "\n",
    "\n",
    "#pandasとして扱う。\n",
    "trainFeature = pd.DataFrame(trainFeature)\n",
    "trainTarget = pd.Series(trainTarget)\n",
    "testFeature = pd.DataFrame(testFeature)\n",
    "testTarget = pd.Series(testTarget)\n",
    "\n",
    "#targetのカラム\n",
    "tarClmn = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'leakyReluSlope': 0.01973893854348531,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: In & Out Type is DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTarget):\n",
    "    #targetを結合\n",
    "    trainFeature = pd.concat([trainFeature, trainTarget], axis=1)\n",
    "    #test側のtargetは0で初期化しておく\n",
    "    testTarTmp = pd.DataFrame(np.zeros((testFeature.shape[0],trainTarget.shape[1]),dtype='uint8'), columns=tarClmn)\n",
    "    testFeature = pd.concat([testFeature, testTarTmp], axis=1)\n",
    "    \n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTarget):\n",
    "    \n",
    "    #targetのデータフレーム作成（列名も付与）(one-hot化しておく)\n",
    "    targetOH = pd.get_dummies(trainTarget)\n",
    "    targetOH.columns = tarClmn\n",
    "    \n",
    "    #train,testにターゲット値を連結。\n",
    "    train, test = Collecting(trainFeature, testFeature, targetOH)\n",
    "    \n",
    "    return train, test, targetOH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 965 ms, sys: 22.9 ms, total: 988 ms\n",
      "Wall time: 987 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  airplane  \\\n",
       "0   59   43   50   68   98  119  139  145  149  149  ...         0   \n",
       "1  154  126  105  102  125  155  172  180  142  111  ...         0   \n",
       "2  255  253  253  253  253  253  253  253  253  253  ...         0   \n",
       "3   28   37   38   42   44   40   40   24   32   43  ...         0   \n",
       "4  170  168  177  183  181  177  181  184  189  189  ...         0   \n",
       "\n",
       "   automobile  bird  cat  deer  dog  frog  horse  ship  truck  \n",
       "0           0     0    0     0    0     1      0     0      0  \n",
       "1           0     0    0     0    0     0      0     0      1  \n",
       "2           0     0    0     0    0     0      0     0      1  \n",
       "3           0     0    0     1    0     0      0     0      0  \n",
       "4           1     0    0     0    0     0      0     0      0  \n",
       "\n",
       "[5 rows x 3082 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>162</td>\n",
       "      <td>159</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>139</td>\n",
       "      <td>132</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>193</td>\n",
       "      <td>199</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>167</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>177</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>166</td>\n",
       "      <td>170</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  airplane  \\\n",
       "0  158  159  165  166  160  156  162  159  158  159  ...         0   \n",
       "1  235  231  232  232  232  232  232  232  232  232  ...         0   \n",
       "2  158  158  139  132  166  182  187  193  199  205  ...         0   \n",
       "3  155  167  176  190  177  166  168  166  170  179  ...         0   \n",
       "4   65   70   48   30   23   40   44   45   45   40  ...         0   \n",
       "\n",
       "   automobile  bird  cat  deer  dog  frog  horse  ship  truck  \n",
       "0           0     0    0     0    0     0      0     0      0  \n",
       "1           0     0    0     0    0     0      0     0      0  \n",
       "2           0     0    0     0    0     0      0     0      0  \n",
       "3           0     0    0     0    0     0      0     0      0  \n",
       "4           0     0    0     0    0     0      0     0      0  \n",
       "\n",
       "[5 rows x 3082 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
       "0         0           0     0    0     0    0     1      0     0      0\n",
       "1         0           0     0    0     0    0     0      0     0      1\n",
       "2         0           0     0    0     0    0     0      0     0      1\n",
       "3         0           0     0    0     1    0     0      0     0      0\n",
       "4         0           1     0    0     0    0     0      0     0      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50000, 3082)\n",
      "Test: (10000, 3082)\n",
      "Target: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \"+ str(trainVsl.shape))\n",
    "print(\"Test: \"+ str(testVsl.shape))\n",
    "print(\"Target: \"+ str(targetVsl.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainVsl, testVsl, targetVsl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(skf.split(X=train, y=trainTarget)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 11.5 ms, total: 1.06 s\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  automobile  bird  \\\n",
       "0   59   43   50   68   98  119  139  145  149  149  ...           0     0   \n",
       "1  154  126  105  102  125  155  172  180  142  111  ...           0     0   \n",
       "2  255  253  253  253  253  253  253  253  253  253  ...           0     0   \n",
       "3   28   37   38   42   44   40   40   24   32   43  ...           0     0   \n",
       "4  170  168  177  183  181  177  181  184  189  189  ...           1     0   \n",
       "\n",
       "   cat  deer  dog  frog  horse  ship  truck  kfold  \n",
       "0    0     0    0     1      0     0      0      0  \n",
       "1    0     0    0     0      0     0      1      0  \n",
       "2    0     0    0     0      0     0      1      0  \n",
       "3    0     1    0     0      0     0      0      0  \n",
       "4    0     0    0     0      0     0      0      0  \n",
       "\n",
       "[5 rows x 3083 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds(trainVsl, targetVsl)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainVsl, testVsl, targetVsl, foldsVsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train,Valid用のデータクラス\n",
    "class TrainDataset:\n",
    "    def __init__(self, features, targets, p: float = 1., transform=None, transformsAug=None):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        #1列のデータを画像としての形に整形\n",
    "        self.features = self.features.reshape(self.features.shape[0], 3, 32, 32).astype(\"uint8\")\n",
    "        #augmentation\n",
    "        self.transform = transform\n",
    "        self.transformsAug = transformsAug\n",
    "        self.p = p #transformの使用有無の判断に使用\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx, :]\n",
    "        \n",
    "        if self.transform:\n",
    "            if random.random() < self.p: #pの値を大きくするほどtransformの使用率が上がる。\n",
    "                augmented = self.transform(image=x)\n",
    "                x = augmented['image']\n",
    "                del augmented\n",
    "        \n",
    "        X = [] #TTA別に画像をリスト化\n",
    "        if self.transformsAug:\n",
    "            for transformAug in self.transformsAug:\n",
    "                augmented = transformAug(image=x)\n",
    "                aug_tmp = torch.tensor(augmented['image'], dtype=torch.float)\n",
    "                X.append(aug_tmp)\n",
    "                del augmented\n",
    "        else:\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "            X.append(x)\n",
    "                        \n",
    "                        \n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : X,\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class ValidDataset:\n",
    "    def __init__(self, features, targets, transforms=None):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        #1列のデータを画像としての形に整形\n",
    "        self.features = self.features.reshape(self.features.shape[0], 3, 32, 32).astype(\"uint8\")\n",
    "        #augmentation\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = [] #TTA別に画像をリスト化\n",
    "        x = self.features[idx, :]\n",
    "        \n",
    "        if self.transforms:\n",
    "            for transform in self.transforms:\n",
    "                augmented = transform(image=x)\n",
    "                aug_tmp = torch.tensor(augmented['image'], dtype=torch.float)\n",
    "                X.append(aug_tmp)\n",
    "                del augmented\n",
    "        else:\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "            X.append(x)\n",
    "                        \n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : X,\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "#Test用のデータクラス\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            #torch.DataLoaderに入れるための形式\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    train_transform = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_Train():\n",
    "    transform1 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    transform2 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(2, 2), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    #transform3 = [\n",
    "    #    #albu.HorizontalFlip(p=1),\n",
    "    #    #albu.VerticalFlip(p=1),\n",
    "    #    albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "    #    #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "    #    #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "    #    #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    #]\n",
    "    \n",
    "    transformsCompo = [\n",
    "        albu.Compose(transform1),\n",
    "        albu.Compose(transform2),\n",
    "        #albu.Compose(transform3),\n",
    "                      ]\n",
    "    \n",
    "    return transformsCompo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_TTA():\n",
    "    transform1 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    transform2 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    #transform3 = [\n",
    "    #    #albu.HorizontalFlip(p=1),\n",
    "    #    #albu.VerticalFlip(p=1),\n",
    "    #    albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "    #    #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "    #    #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "    #    #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    #]\n",
    "    \n",
    "    transformsCompo = [\n",
    "        albu.Compose(transform1),\n",
    "        albu.Compose(transform2),\n",
    "        #albu.Compose(transform3),\n",
    "                      ]\n",
    "    \n",
    "    return transformsCompo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ここを有効にすると何故か本番で違う挙動をするのでtest時以外はコメントアウトしておくこと ##############\n",
    "#transformsVsl = get_augmentation()\n",
    "#\n",
    "#trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)\n",
    "#foldsVsl = CV_folds(trainVsl, targetVsl)\n",
    "#confFitting = Config_about_Fitting(trainVsl, testVsl, targetVsl, foldsVsl)\n",
    "#imgOrg = foldsVsl[confFitting[\"feature_cols\"]].values[0]\n",
    "#imgOrg = imgOrg.reshape(3, 32, 32).transpose(1, 2, 0).astype(\"uint8\")\n",
    "#\n",
    "#imgTrs = imgOrg.copy()\n",
    "#augmented = transformsVsl(image=imgTrs)\n",
    "#del transformsVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.axis('off')\n",
    "#plt.imshow(imgOrg)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.axis('off')\n",
    "#plt.imshow(augmented['image'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "#nn.BCEWithLogitsLoss()\n",
    "\n",
    "#class LabelSmoothingCrossEntropy(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "#    def forward(self, x, target, smoothing=0.001):\n",
    "#        confidence = 1. - smoothing\n",
    "#        logprobs = F.log_softmax(x, dim=-1)\n",
    "#        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n",
    "#        smooth_loss = -logprobs.mean(dim=-1)\n",
    "#        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "#        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "#nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: Fitting, Evaluation, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    global IMG_VSL_FLG_TRAIN\n",
    "    \n",
    "    for data in dataloader:\n",
    "        targets = data['y'].to(device)\n",
    "        outputs = torch.zeros_like(targets)\n",
    "        \n",
    "        #Augmentation Imageごとに予測\n",
    "        for dataAug in data['x']:\n",
    "            #imageの可視化(最初のデータだけ)\n",
    "            if IMG_VSL_FLG_TRAIN:\n",
    "                img = dataAug[0].detach().cpu().numpy().transpose(1, 2, 0).astype(\"uint8\").copy()\n",
    "                plt.axis('off')\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "                del img\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            inputs = dataAug.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            final_loss += loss.item()\n",
    "        \n",
    "        IMG_VSL_FLG_TRAIN = False\n",
    "    \n",
    "    final_loss = final_loss / (len(dataloader)*len(data['x']))\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    global IMG_VSL_FLG_VALID\n",
    "    \n",
    "    #batchごとの処理\n",
    "    for data in dataloader:\n",
    "        targets = data['y'].to(device)\n",
    "        outputs = torch.zeros_like(targets)\n",
    "        \n",
    "        #Augmentation Imageごとに予測\n",
    "        for dataAug in data['x']:\n",
    "            #imageの可視化(最初のデータだけ)\n",
    "            if IMG_VSL_FLG_VALID:\n",
    "                img = dataAug[0].detach().cpu().numpy().transpose(1, 2, 0).astype(\"uint8\").copy()\n",
    "                plt.axis('off')\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "                del img\n",
    "                            \n",
    "            inputs = dataAug.to(device)\n",
    "            output = model(inputs)\n",
    "            outputs += output\n",
    "        \n",
    "        IMG_VSL_FLG_VALID = False\n",
    "        outputs /= len(data['x']) #それぞれの予測を平均化（Test Time Augmentation）\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 3, 1, 1)\n",
    "x.shape\n",
    "x.view(-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, param):\n",
    "        super(Model, self).__init__()\n",
    "        #-------------------前準備---------------------------------------------------------------------\n",
    "        self.layersCompo = lambda in_ch, out_ch: [torch.nn.Conv2d(in_ch,  # チャネル入力（色の部分）\n",
    "                                                            out_ch,  # チャンネル出力\n",
    "                                                            3,       # カーネルサイズ(フィルタサイズ)\n",
    "                                                            1,       # ストライド (デフォルトは1)\n",
    "                                                            1,       # パディング (デフォルトは0)\n",
    "                                                            ), \n",
    "                                                  nn.BatchNorm2d(out_ch),\n",
    "                                                  nn.ReLU(),\n",
    "                                                  nn.Dropout(p=0.3)]\n",
    "        \n",
    "        layersList = []\n",
    "        \n",
    "        layersList.extend(self.layersCompo(3, 64))\n",
    "        layersList.extend(self.layersCompo(64, 64))\n",
    "        layersList.extend(self.layersCompo(64, 64))\n",
    "        layersList.append(torch.nn.AvgPool2d(2)) # カーネルサイズ\n",
    "        \n",
    "        layersList.extend(self.layersCompo(64, 128))\n",
    "        layersList.extend(self.layersCompo(128, 128))\n",
    "        layersList.extend(self.layersCompo(128, 128))\n",
    "        layersList.append(torch.nn.AvgPool2d(2)) # カーネルサイズ\n",
    "\n",
    "        layersList.extend(self.layersCompo(128, 256))\n",
    "        layersList.extend(self.layersCompo(256, 256))\n",
    "        layersList.extend(self.layersCompo(256, 256))\n",
    "        \n",
    "        \n",
    "        #------------------モデル--------------------------------------------------------------------------\n",
    "        self.layers = nn.ModuleList(layersList) \n",
    "        #F.avg_pool2d(x, kernel_size=x.size()[2:]) #Grobal average pooling　（画像面ごとにまとめる）\n",
    "        \n",
    "        self.dense1 = nn.Linear(256, num_targets)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            #print(x.shape)\n",
    "            x = self.layers[i](x)\n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.view(-1,256)#[512,256,1,1]->[512,256]\n",
    "        #print(x.shape)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, Plotting, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]].values, train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]].values, valid_df[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    #aumentation\n",
    "    transforms = get_transform()\n",
    "    train_aumentation = get_augmentation_Train()\n",
    "    valid_aumentation = get_augmentation_TTA()\n",
    "    \n",
    "    train_dataset = TrainDataset(x_train, y_train, AUGMENT_PRB, transforms, train_aumentation)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid, AUGMENT_PRB, transforms, valid_aumentation)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        #arch=ARCH,\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader)*len(train_aumentation))\n",
    "    #scheduler = sch.CosineAnnealingWarmupRestarts(optimizer,\n",
    "    #                                              first_cycle_steps=200,\n",
    "    #                                              cycle_mult=1.0,\n",
    "    #                                              max_lr=0.01,\n",
    "    #                                              min_lr=0.0001,\n",
    "    #                                              warmup_steps=50,\n",
    "    #                                              gamma=0.5)\n",
    "    \n",
    "    ##### 評価関数 ######\n",
    "    train_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    valid_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.shape[1]))\n",
    "    best_loss = np.inf\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'valid_loss': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, train_loss_fn, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, valid_loss_fn, validloader, DEVICE)\n",
    "        if Tester:\n",
    "            print(\"EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(epoch, train_loss, valid_loss))\n",
    "                \n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_epoch = epoch\n",
    "            best_train_loss = train_loss\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                if Tester:\n",
    "                    print('Early stopping. Best Val loss: {:.3f}'.format(best_loss))\n",
    "                break\n",
    "            \n",
    "    print(\"<BEST LOSS> EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(best_epoch, best_train_loss, best_loss))\n",
    "    \n",
    "    #Visuarization\n",
    "    if Plotting:\n",
    "        plt.plot(range(1, len(history['train_loss']) + 1), history['train_loss'], label='train_loss')\n",
    "        plt.plot(range(1, len(history['valid_loss']) + 1), history['valid_loss'], label='valid_loss')\n",
    "        plt.title(f'Seed{seed} Fold{fold} LOSS VISUARIZATION')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{SAVEPLOT}Seed{seed}_Fold{fold}_history.png')\n",
    "        plt.close()\n",
    "    \n",
    "    del history\n",
    "    \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    #x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    #testdataset = TestDataset(x_test)\n",
    "    #testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #\n",
    "    #model = Model(\n",
    "    #    num_features=confFitting[\"num_features\"],\n",
    "    #    num_targets=confFitting[\"num_targets\"],\n",
    "    #    arch=ARCH,\n",
    "    #    param=param\n",
    "    #)\n",
    "    #\n",
    "    #model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    #model.to(DEVICE)\n",
    "    #\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    #predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, Plotting, NFOLDS, seed, param,\n",
    "              folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, Plotting, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, target):\n",
    "    score = []\n",
    "    \n",
    "    #cross entropy\n",
    "    y_true_OH = target[confFitting[\"target_cols\"]].values\n",
    "    y_pred_proba = oof\n",
    "    \n",
    "    score_logloss = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true_OH[:, i], y_pred_proba[:, i]) #問題の評価指標によって変わる。\n",
    "        score_logloss += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV cross entropy: \", score_logloss)\n",
    "    score.append(score_logloss)\n",
    "    \n",
    "    \n",
    "    #accuracy\n",
    "    score_accuracy = 0\n",
    "    y_true = trainTarget.values\n",
    "    y_pred= np.zeros((trainTarget.shape[0],))\n",
    "    for i in range(trainTarget.shape[0]):\n",
    "        #pred_proba->predに変形\n",
    "        y_pred[i] = np.argmax(oof[i])\n",
    "    \n",
    "    score_accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"CV accuracy: \", score_accuracy)\n",
    "    score.append(score_accuracy)\n",
    "    \n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', y_pred_proba)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Plot(True/False)\n",
    "    Plotting = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTarget)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [42]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, Plotting, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score, oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 42 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.348\n",
      "EPOCH: 001: | train_loss: 0.270: | valid_loss: 0.269\n",
      "EPOCH: 002: | train_loss: 0.202: | valid_loss: 0.309\n",
      "EPOCH: 003: | train_loss: 0.169: | valid_loss: 0.704\n",
      "EPOCH: 004: | train_loss: 0.144: | valid_loss: 0.307\n",
      "EPOCH: 005: | train_loss: 0.128: | valid_loss: 0.188\n",
      "EPOCH: 006: | train_loss: 0.113: | valid_loss: 0.242\n",
      "EPOCH: 007: | train_loss: 0.107: | valid_loss: 0.293\n",
      "EPOCH: 008: | train_loss: 0.099: | valid_loss: 0.294\n",
      "EPOCH: 009: | train_loss: 0.095: | valid_loss: 0.367\n",
      "EPOCH: 010: | train_loss: 0.089: | valid_loss: 0.286\n",
      "EPOCH: 011: | train_loss: 0.086: | valid_loss: 0.473\n",
      "EPOCH: 012: | train_loss: 0.086: | valid_loss: 0.130\n",
      "EPOCH: 013: | train_loss: 0.079: | valid_loss: 0.372\n",
      "EPOCH: 014: | train_loss: 0.082: | valid_loss: 0.211\n",
      "EPOCH: 015: | train_loss: 0.080: | valid_loss: 0.202\n",
      "EPOCH: 016: | train_loss: 0.077: | valid_loss: 0.208\n",
      "EPOCH: 017: | train_loss: 0.077: | valid_loss: 0.204\n",
      "EPOCH: 018: | train_loss: 0.075: | valid_loss: 0.223\n",
      "EPOCH: 019: | train_loss: 0.079: | valid_loss: 0.330\n",
      "EPOCH: 020: | train_loss: 0.075: | valid_loss: 0.275\n",
      "EPOCH: 021: | train_loss: 0.074: | valid_loss: 0.168\n",
      "EPOCH: 022: | train_loss: 0.070: | valid_loss: 0.123\n",
      "EPOCH: 023: | train_loss: 0.067: | valid_loss: 0.253\n",
      "EPOCH: 024: | train_loss: 0.070: | valid_loss: 0.206\n",
      "EPOCH: 025: | train_loss: 0.070: | valid_loss: 0.149\n",
      "EPOCH: 026: | train_loss: 0.068: | valid_loss: 0.153\n",
      "EPOCH: 027: | train_loss: 0.068: | valid_loss: 0.181\n",
      "EPOCH: 028: | train_loss: 0.066: | valid_loss: 0.247\n",
      "EPOCH: 029: | train_loss: 0.070: | valid_loss: 0.269\n",
      "EPOCH: 030: | train_loss: 0.071: | valid_loss: 0.144\n",
      "EPOCH: 031: | train_loss: 0.065: | valid_loss: 0.133\n",
      "EPOCH: 032: | train_loss: 0.061: | valid_loss: 0.122\n",
      "EPOCH: 033: | train_loss: 0.061: | valid_loss: 0.100\n",
      "EPOCH: 034: | train_loss: 0.058: | valid_loss: 0.131\n",
      "EPOCH: 035: | train_loss: 0.057: | valid_loss: 0.141\n",
      "EPOCH: 036: | train_loss: 0.056: | valid_loss: 0.105\n",
      "EPOCH: 037: | train_loss: 0.057: | valid_loss: 0.095\n",
      "EPOCH: 038: | train_loss: 0.055: | valid_loss: 0.108\n",
      "EPOCH: 039: | train_loss: 0.058: | valid_loss: 0.122\n",
      "EPOCH: 040: | train_loss: 0.056: | valid_loss: 0.087\n",
      "EPOCH: 041: | train_loss: 0.051: | valid_loss: 0.091\n",
      "EPOCH: 042: | train_loss: 0.047: | valid_loss: 0.090\n",
      "EPOCH: 043: | train_loss: 0.048: | valid_loss: 0.091\n",
      "EPOCH: 044: | train_loss: 0.051: | valid_loss: 0.086\n",
      "EPOCH: 045: | train_loss: 0.051: | valid_loss: 0.080\n",
      "EPOCH: 046: | train_loss: 0.044: | valid_loss: 0.080\n",
      "EPOCH: 047: | train_loss: 0.044: | valid_loss: 0.081\n",
      "EPOCH: 048: | train_loss: 0.039: | valid_loss: 0.072\n",
      "EPOCH: 049: | train_loss: 0.038: | valid_loss: 0.082\n",
      "EPOCH: 050: | train_loss: 0.038: | valid_loss: 0.077\n",
      "EPOCH: 051: | train_loss: 0.038: | valid_loss: 0.072\n",
      "EPOCH: 052: | train_loss: 0.033: | valid_loss: 0.067\n",
      "EPOCH: 053: | train_loss: 0.033: | valid_loss: 0.072\n",
      "EPOCH: 054: | train_loss: 0.027: | valid_loss: 0.069\n",
      "EPOCH: 055: | train_loss: 0.026: | valid_loss: 0.068\n",
      "EPOCH: 056: | train_loss: 0.025: | valid_loss: 0.067\n",
      "EPOCH: 057: | train_loss: 0.028: | valid_loss: 0.065\n",
      "EPOCH: 058: | train_loss: 0.025: | valid_loss: 0.063\n",
      "EPOCH: 059: | train_loss: 0.024: | valid_loss: 0.065\n",
      "EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.060\n",
      "EPOCH: 061: | train_loss: 0.018: | valid_loss: 0.065\n",
      "EPOCH: 062: | train_loss: 0.018: | valid_loss: 0.063\n",
      "EPOCH: 063: | train_loss: 0.016: | valid_loss: 0.061\n",
      "EPOCH: 064: | train_loss: 0.015: | valid_loss: 0.064\n",
      "EPOCH: 065: | train_loss: 0.014: | valid_loss: 0.065\n",
      "EPOCH: 066: | train_loss: 0.012: | valid_loss: 0.061\n",
      "EPOCH: 067: | train_loss: 0.012: | valid_loss: 0.064\n",
      "EPOCH: 068: | train_loss: 0.012: | valid_loss: 0.065\n",
      "EPOCH: 069: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 070: | train_loss: 0.011: | valid_loss: 0.065\n",
      "EPOCH: 071: | train_loss: 0.010: | valid_loss: 0.063\n",
      "EPOCH: 072: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 073: | train_loss: 0.010: | valid_loss: 0.064\n",
      "EPOCH: 074: | train_loss: 0.010: | valid_loss: 0.062\n",
      "<BEST LOSS> EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.060\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.358\n",
      "EPOCH: 001: | train_loss: 0.270: | valid_loss: 0.374\n",
      "EPOCH: 002: | train_loss: 0.203: | valid_loss: 0.369\n",
      "EPOCH: 003: | train_loss: 0.171: | valid_loss: 0.499\n",
      "EPOCH: 004: | train_loss: 0.146: | valid_loss: 0.315\n",
      "EPOCH: 005: | train_loss: 0.132: | valid_loss: 0.462\n",
      "EPOCH: 006: | train_loss: 0.115: | valid_loss: 0.352\n",
      "EPOCH: 007: | train_loss: 0.105: | valid_loss: 0.239\n",
      "EPOCH: 008: | train_loss: 0.099: | valid_loss: 0.295\n",
      "EPOCH: 009: | train_loss: 0.100: | valid_loss: 0.360\n",
      "EPOCH: 010: | train_loss: 0.091: | valid_loss: 0.254\n",
      "EPOCH: 011: | train_loss: 0.087: | valid_loss: 0.401\n",
      "EPOCH: 012: | train_loss: 0.090: | valid_loss: 0.150\n",
      "EPOCH: 013: | train_loss: 0.081: | valid_loss: 0.212\n",
      "EPOCH: 014: | train_loss: 0.082: | valid_loss: 0.273\n",
      "EPOCH: 015: | train_loss: 0.080: | valid_loss: 0.221\n",
      "EPOCH: 016: | train_loss: 0.076: | valid_loss: 0.193\n",
      "EPOCH: 017: | train_loss: 0.077: | valid_loss: 0.252\n",
      "EPOCH: 018: | train_loss: 0.078: | valid_loss: 0.155\n",
      "EPOCH: 019: | train_loss: 0.077: | valid_loss: 0.149\n",
      "EPOCH: 020: | train_loss: 0.074: | valid_loss: 0.206\n",
      "EPOCH: 021: | train_loss: 0.072: | valid_loss: 0.181\n",
      "EPOCH: 022: | train_loss: 0.070: | valid_loss: 0.247\n",
      "EPOCH: 023: | train_loss: 0.069: | valid_loss: 0.193\n",
      "EPOCH: 024: | train_loss: 0.072: | valid_loss: 0.162\n",
      "EPOCH: 025: | train_loss: 0.071: | valid_loss: 0.128\n",
      "EPOCH: 026: | train_loss: 0.067: | valid_loss: 0.181\n",
      "EPOCH: 027: | train_loss: 0.067: | valid_loss: 0.135\n",
      "EPOCH: 028: | train_loss: 0.065: | valid_loss: 0.205\n",
      "EPOCH: 029: | train_loss: 0.068: | valid_loss: 0.228\n",
      "EPOCH: 030: | train_loss: 0.074: | valid_loss: 0.106\n",
      "EPOCH: 031: | train_loss: 0.065: | valid_loss: 0.168\n",
      "EPOCH: 032: | train_loss: 0.067: | valid_loss: 0.120\n",
      "EPOCH: 033: | train_loss: 0.061: | valid_loss: 0.103\n",
      "EPOCH: 034: | train_loss: 0.058: | valid_loss: 0.141\n",
      "EPOCH: 035: | train_loss: 0.056: | valid_loss: 0.109\n",
      "EPOCH: 036: | train_loss: 0.057: | valid_loss: 0.106\n",
      "EPOCH: 037: | train_loss: 0.057: | valid_loss: 0.103\n",
      "EPOCH: 038: | train_loss: 0.054: | valid_loss: 0.112\n",
      "EPOCH: 039: | train_loss: 0.053: | valid_loss: 0.128\n",
      "EPOCH: 040: | train_loss: 0.055: | valid_loss: 0.128\n",
      "EPOCH: 041: | train_loss: 0.049: | valid_loss: 0.091\n",
      "EPOCH: 042: | train_loss: 0.048: | valid_loss: 0.086\n",
      "EPOCH: 043: | train_loss: 0.048: | valid_loss: 0.102\n",
      "EPOCH: 044: | train_loss: 0.050: | valid_loss: 0.098\n",
      "EPOCH: 045: | train_loss: 0.049: | valid_loss: 0.076\n",
      "EPOCH: 046: | train_loss: 0.045: | valid_loss: 0.095\n",
      "EPOCH: 047: | train_loss: 0.044: | valid_loss: 0.082\n",
      "EPOCH: 048: | train_loss: 0.042: | valid_loss: 0.093\n",
      "EPOCH: 049: | train_loss: 0.043: | valid_loss: 0.074\n",
      "EPOCH: 050: | train_loss: 0.037: | valid_loss: 0.098\n",
      "EPOCH: 051: | train_loss: 0.037: | valid_loss: 0.104\n",
      "EPOCH: 052: | train_loss: 0.033: | valid_loss: 0.076\n",
      "EPOCH: 053: | train_loss: 0.032: | valid_loss: 0.066\n",
      "EPOCH: 054: | train_loss: 0.030: | valid_loss: 0.067\n",
      "EPOCH: 055: | train_loss: 0.026: | valid_loss: 0.068\n",
      "EPOCH: 056: | train_loss: 0.025: | valid_loss: 0.066\n",
      "EPOCH: 057: | train_loss: 0.025: | valid_loss: 0.063\n",
      "EPOCH: 058: | train_loss: 0.027: | valid_loss: 0.068\n",
      "EPOCH: 059: | train_loss: 0.022: | valid_loss: 0.061\n",
      "EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.062\n",
      "EPOCH: 061: | train_loss: 0.017: | valid_loss: 0.063\n",
      "EPOCH: 062: | train_loss: 0.017: | valid_loss: 0.069\n",
      "EPOCH: 063: | train_loss: 0.015: | valid_loss: 0.064\n",
      "EPOCH: 064: | train_loss: 0.015: | valid_loss: 0.065\n",
      "EPOCH: 065: | train_loss: 0.013: | valid_loss: 0.066\n",
      "EPOCH: 066: | train_loss: 0.012: | valid_loss: 0.063\n",
      "EPOCH: 067: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 068: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 069: | train_loss: 0.011: | valid_loss: 0.064\n",
      "EPOCH: 070: | train_loss: 0.010: | valid_loss: 0.067\n",
      "EPOCH: 071: | train_loss: 0.010: | valid_loss: 0.065\n",
      "EPOCH: 072: | train_loss: 0.010: | valid_loss: 0.066\n",
      "EPOCH: 073: | train_loss: 0.009: | valid_loss: 0.066\n",
      "EPOCH: 074: | train_loss: 0.010: | valid_loss: 0.065\n",
      "<BEST LOSS> EPOCH: 059: | train_loss: 0.022: | valid_loss: 0.061\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 001: | train_loss: 0.271: | valid_loss: 0.294\n",
      "EPOCH: 002: | train_loss: 0.205: | valid_loss: 0.398\n",
      "EPOCH: 003: | train_loss: 0.171: | valid_loss: 0.540\n",
      "EPOCH: 004: | train_loss: 0.148: | valid_loss: 0.330\n",
      "EPOCH: 005: | train_loss: 0.133: | valid_loss: 0.355\n",
      "EPOCH: 006: | train_loss: 0.116: | valid_loss: 0.286\n",
      "EPOCH: 007: | train_loss: 0.106: | valid_loss: 0.434\n",
      "EPOCH: 008: | train_loss: 0.099: | valid_loss: 0.493\n",
      "EPOCH: 009: | train_loss: 0.096: | valid_loss: 0.376\n",
      "EPOCH: 010: | train_loss: 0.089: | valid_loss: 0.227\n",
      "EPOCH: 011: | train_loss: 0.088: | valid_loss: 0.317\n",
      "EPOCH: 012: | train_loss: 0.095: | valid_loss: 0.172\n",
      "EPOCH: 013: | train_loss: 0.085: | valid_loss: 0.296\n",
      "EPOCH: 014: | train_loss: 0.082: | valid_loss: 0.183\n",
      "EPOCH: 015: | train_loss: 0.078: | valid_loss: 0.196\n",
      "EPOCH: 016: | train_loss: 0.079: | valid_loss: 0.231\n",
      "EPOCH: 017: | train_loss: 0.077: | valid_loss: 0.178\n",
      "EPOCH: 018: | train_loss: 0.075: | valid_loss: 0.237\n",
      "EPOCH: 019: | train_loss: 0.079: | valid_loss: 0.409\n",
      "EPOCH: 020: | train_loss: 0.079: | valid_loss: 0.163\n",
      "EPOCH: 021: | train_loss: 0.073: | valid_loss: 0.262\n",
      "EPOCH: 022: | train_loss: 0.073: | valid_loss: 0.152\n",
      "EPOCH: 023: | train_loss: 0.068: | valid_loss: 0.125\n",
      "EPOCH: 024: | train_loss: 0.070: | valid_loss: 0.203\n",
      "EPOCH: 025: | train_loss: 0.071: | valid_loss: 0.171\n",
      "EPOCH: 026: | train_loss: 0.070: | valid_loss: 0.255\n",
      "EPOCH: 027: | train_loss: 0.071: | valid_loss: 0.113\n",
      "EPOCH: 028: | train_loss: 0.065: | valid_loss: 0.148\n",
      "EPOCH: 029: | train_loss: 0.068: | valid_loss: 0.253\n",
      "EPOCH: 030: | train_loss: 0.069: | valid_loss: 0.114\n",
      "EPOCH: 031: | train_loss: 0.066: | valid_loss: 0.120\n",
      "EPOCH: 032: | train_loss: 0.063: | valid_loss: 0.124\n",
      "EPOCH: 033: | train_loss: 0.061: | valid_loss: 0.218\n",
      "EPOCH: 034: | train_loss: 0.059: | valid_loss: 0.106\n",
      "EPOCH: 035: | train_loss: 0.060: | valid_loss: 0.106\n",
      "EPOCH: 036: | train_loss: 0.058: | valid_loss: 0.111\n",
      "EPOCH: 037: | train_loss: 0.058: | valid_loss: 0.111\n",
      "EPOCH: 038: | train_loss: 0.055: | valid_loss: 0.108\n",
      "EPOCH: 039: | train_loss: 0.060: | valid_loss: 0.118\n",
      "EPOCH: 040: | train_loss: 0.058: | valid_loss: 0.089\n",
      "EPOCH: 041: | train_loss: 0.052: | valid_loss: 0.110\n",
      "EPOCH: 042: | train_loss: 0.050: | valid_loss: 0.091\n",
      "EPOCH: 043: | train_loss: 0.053: | valid_loss: 0.091\n",
      "EPOCH: 044: | train_loss: 0.052: | valid_loss: 0.087\n",
      "EPOCH: 045: | train_loss: 0.050: | valid_loss: 0.092\n",
      "EPOCH: 046: | train_loss: 0.046: | valid_loss: 0.098\n",
      "EPOCH: 047: | train_loss: 0.048: | valid_loss: 0.076\n",
      "EPOCH: 048: | train_loss: 0.041: | valid_loss: 0.113\n",
      "EPOCH: 049: | train_loss: 0.040: | valid_loss: 0.070\n",
      "EPOCH: 050: | train_loss: 0.038: | valid_loss: 0.072\n",
      "EPOCH: 051: | train_loss: 0.036: | valid_loss: 0.073\n",
      "EPOCH: 052: | train_loss: 0.035: | valid_loss: 0.068\n",
      "EPOCH: 053: | train_loss: 0.032: | valid_loss: 0.066\n",
      "EPOCH: 054: | train_loss: 0.029: | valid_loss: 0.066\n",
      "EPOCH: 055: | train_loss: 0.028: | valid_loss: 0.066\n",
      "EPOCH: 056: | train_loss: 0.028: | valid_loss: 0.070\n",
      "EPOCH: 057: | train_loss: 0.027: | valid_loss: 0.072\n",
      "EPOCH: 058: | train_loss: 0.025: | valid_loss: 0.067\n",
      "EPOCH: 059: | train_loss: 0.023: | valid_loss: 0.063\n",
      "EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.061\n",
      "EPOCH: 061: | train_loss: 0.019: | valid_loss: 0.062\n",
      "EPOCH: 062: | train_loss: 0.018: | valid_loss: 0.065\n",
      "EPOCH: 063: | train_loss: 0.017: | valid_loss: 0.063\n",
      "EPOCH: 064: | train_loss: 0.016: | valid_loss: 0.065\n",
      "EPOCH: 065: | train_loss: 0.014: | valid_loss: 0.061\n",
      "EPOCH: 066: | train_loss: 0.014: | valid_loss: 0.059\n",
      "EPOCH: 067: | train_loss: 0.013: | valid_loss: 0.062\n",
      "EPOCH: 068: | train_loss: 0.012: | valid_loss: 0.061\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.061\n",
      "EPOCH: 070: | train_loss: 0.011: | valid_loss: 0.062\n",
      "EPOCH: 071: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 072: | train_loss: 0.011: | valid_loss: 0.061\n",
      "EPOCH: 073: | train_loss: 0.011: | valid_loss: 0.063\n",
      "EPOCH: 074: | train_loss: 0.010: | valid_loss: 0.062\n",
      "<BEST LOSS> EPOCH: 066: | train_loss: 0.014: | valid_loss: 0.059\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.568: | valid_loss: 0.356\n",
      "EPOCH: 001: | train_loss: 0.271: | valid_loss: 0.277\n",
      "EPOCH: 002: | train_loss: 0.204: | valid_loss: 0.522\n",
      "EPOCH: 003: | train_loss: 0.170: | valid_loss: 0.459\n",
      "EPOCH: 004: | train_loss: 0.152: | valid_loss: 0.440\n",
      "EPOCH: 005: | train_loss: 0.131: | valid_loss: 0.325\n",
      "EPOCH: 006: | train_loss: 0.118: | valid_loss: 0.274\n",
      "EPOCH: 007: | train_loss: 0.108: | valid_loss: 0.263\n",
      "EPOCH: 008: | train_loss: 0.099: | valid_loss: 0.498\n",
      "EPOCH: 009: | train_loss: 0.096: | valid_loss: 0.330\n",
      "EPOCH: 010: | train_loss: 0.093: | valid_loss: 0.188\n",
      "EPOCH: 011: | train_loss: 0.086: | valid_loss: 0.224\n",
      "EPOCH: 012: | train_loss: 0.088: | valid_loss: 0.182\n",
      "EPOCH: 013: | train_loss: 0.082: | valid_loss: 0.430\n",
      "EPOCH: 014: | train_loss: 0.084: | valid_loss: 0.345\n",
      "EPOCH: 015: | train_loss: 0.081: | valid_loss: 0.394\n",
      "EPOCH: 016: | train_loss: 0.081: | valid_loss: 0.206\n",
      "EPOCH: 017: | train_loss: 0.078: | valid_loss: 0.240\n",
      "EPOCH: 018: | train_loss: 0.077: | valid_loss: 0.253\n",
      "EPOCH: 019: | train_loss: 0.075: | valid_loss: 0.271\n",
      "EPOCH: 020: | train_loss: 0.077: | valid_loss: 0.218\n",
      "EPOCH: 021: | train_loss: 0.076: | valid_loss: 0.213\n",
      "EPOCH: 022: | train_loss: 0.072: | valid_loss: 0.213\n",
      "EPOCH: 023: | train_loss: 0.072: | valid_loss: 0.225\n",
      "EPOCH: 024: | train_loss: 0.070: | valid_loss: 0.282\n",
      "EPOCH: 025: | train_loss: 0.072: | valid_loss: 0.183\n",
      "EPOCH: 026: | train_loss: 0.070: | valid_loss: 0.230\n",
      "EPOCH: 027: | train_loss: 0.068: | valid_loss: 0.111\n",
      "EPOCH: 028: | train_loss: 0.067: | valid_loss: 0.136\n",
      "EPOCH: 029: | train_loss: 0.071: | valid_loss: 0.156\n",
      "EPOCH: 030: | train_loss: 0.066: | valid_loss: 0.120\n",
      "EPOCH: 031: | train_loss: 0.066: | valid_loss: 0.108\n",
      "EPOCH: 032: | train_loss: 0.060: | valid_loss: 0.120\n",
      "EPOCH: 033: | train_loss: 0.060: | valid_loss: 0.157\n",
      "EPOCH: 034: | train_loss: 0.058: | valid_loss: 0.132\n",
      "EPOCH: 035: | train_loss: 0.058: | valid_loss: 0.114\n",
      "EPOCH: 036: | train_loss: 0.058: | valid_loss: 0.109\n",
      "EPOCH: 037: | train_loss: 0.054: | valid_loss: 0.103\n",
      "EPOCH: 038: | train_loss: 0.056: | valid_loss: 0.109\n",
      "EPOCH: 039: | train_loss: 0.056: | valid_loss: 0.145\n",
      "EPOCH: 040: | train_loss: 0.058: | valid_loss: 0.100\n",
      "EPOCH: 041: | train_loss: 0.050: | valid_loss: 0.092\n",
      "EPOCH: 042: | train_loss: 0.052: | valid_loss: 0.087\n",
      "EPOCH: 043: | train_loss: 0.048: | valid_loss: 0.094\n",
      "EPOCH: 044: | train_loss: 0.048: | valid_loss: 0.090\n",
      "EPOCH: 045: | train_loss: 0.046: | valid_loss: 0.075\n",
      "EPOCH: 046: | train_loss: 0.043: | valid_loss: 0.097\n",
      "EPOCH: 047: | train_loss: 0.048: | valid_loss: 0.095\n",
      "EPOCH: 048: | train_loss: 0.042: | valid_loss: 0.080\n",
      "EPOCH: 049: | train_loss: 0.043: | valid_loss: 0.081\n",
      "EPOCH: 050: | train_loss: 0.043: | valid_loss: 0.077\n",
      "EPOCH: 051: | train_loss: 0.035: | valid_loss: 0.074\n",
      "EPOCH: 052: | train_loss: 0.033: | valid_loss: 0.068\n",
      "EPOCH: 053: | train_loss: 0.032: | valid_loss: 0.066\n",
      "EPOCH: 054: | train_loss: 0.030: | valid_loss: 0.064\n",
      "EPOCH: 055: | train_loss: 0.030: | valid_loss: 0.071\n",
      "EPOCH: 056: | train_loss: 0.029: | valid_loss: 0.070\n",
      "EPOCH: 057: | train_loss: 0.028: | valid_loss: 0.069\n",
      "EPOCH: 058: | train_loss: 0.023: | valid_loss: 0.061\n",
      "EPOCH: 059: | train_loss: 0.020: | valid_loss: 0.068\n",
      "EPOCH: 060: | train_loss: 0.019: | valid_loss: 0.062\n",
      "EPOCH: 061: | train_loss: 0.019: | valid_loss: 0.065\n",
      "EPOCH: 062: | train_loss: 0.017: | valid_loss: 0.062\n",
      "EPOCH: 063: | train_loss: 0.016: | valid_loss: 0.062\n",
      "EPOCH: 064: | train_loss: 0.015: | valid_loss: 0.066\n",
      "EPOCH: 065: | train_loss: 0.014: | valid_loss: 0.062\n",
      "EPOCH: 066: | train_loss: 0.013: | valid_loss: 0.062\n",
      "EPOCH: 067: | train_loss: 0.013: | valid_loss: 0.065\n",
      "EPOCH: 068: | train_loss: 0.012: | valid_loss: 0.063\n",
      "EPOCH: 069: | train_loss: 0.011: | valid_loss: 0.065\n",
      "EPOCH: 070: | train_loss: 0.011: | valid_loss: 0.065\n",
      "EPOCH: 071: | train_loss: 0.011: | valid_loss: 0.066\n",
      "EPOCH: 072: | train_loss: 0.010: | valid_loss: 0.063\n",
      "EPOCH: 073: | train_loss: 0.010: | valid_loss: 0.062\n",
      "EPOCH: 074: | train_loss: 0.010: | valid_loss: 0.063\n",
      "<BEST LOSS> EPOCH: 058: | train_loss: 0.023: | valid_loss: 0.061\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.569: | valid_loss: 0.362\n",
      "EPOCH: 001: | train_loss: 0.270: | valid_loss: 0.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 002: | train_loss: 0.205: | valid_loss: 0.385\n",
      "EPOCH: 003: | train_loss: 0.175: | valid_loss: 0.288\n",
      "EPOCH: 004: | train_loss: 0.154: | valid_loss: 0.273\n",
      "EPOCH: 005: | train_loss: 0.137: | valid_loss: 0.492\n",
      "EPOCH: 006: | train_loss: 0.120: | valid_loss: 0.310\n",
      "EPOCH: 007: | train_loss: 0.111: | valid_loss: 0.294\n",
      "EPOCH: 008: | train_loss: 0.105: | valid_loss: 0.500\n",
      "EPOCH: 009: | train_loss: 0.098: | valid_loss: 0.333\n",
      "EPOCH: 010: | train_loss: 0.094: | valid_loss: 0.349\n",
      "EPOCH: 011: | train_loss: 0.089: | valid_loss: 0.202\n",
      "EPOCH: 012: | train_loss: 0.088: | valid_loss: 0.224\n",
      "EPOCH: 013: | train_loss: 0.082: | valid_loss: 0.300\n",
      "EPOCH: 014: | train_loss: 0.083: | valid_loss: 0.239\n",
      "EPOCH: 015: | train_loss: 0.079: | valid_loss: 0.222\n",
      "EPOCH: 016: | train_loss: 0.081: | valid_loss: 0.278\n",
      "EPOCH: 017: | train_loss: 0.080: | valid_loss: 0.198\n",
      "EPOCH: 018: | train_loss: 0.079: | valid_loss: 0.226\n",
      "EPOCH: 019: | train_loss: 0.080: | valid_loss: 0.386\n",
      "EPOCH: 020: | train_loss: 0.079: | valid_loss: 0.139\n",
      "EPOCH: 021: | train_loss: 0.071: | valid_loss: 0.190\n",
      "EPOCH: 022: | train_loss: 0.072: | valid_loss: 0.183\n",
      "EPOCH: 023: | train_loss: 0.076: | valid_loss: 0.138\n",
      "EPOCH: 024: | train_loss: 0.073: | valid_loss: 0.146\n",
      "EPOCH: 025: | train_loss: 0.070: | valid_loss: 0.159\n",
      "EPOCH: 026: | train_loss: 0.070: | valid_loss: 0.158\n",
      "EPOCH: 027: | train_loss: 0.067: | valid_loss: 0.139\n",
      "EPOCH: 028: | train_loss: 0.066: | valid_loss: 0.143\n",
      "EPOCH: 029: | train_loss: 0.069: | valid_loss: 0.178\n",
      "EPOCH: 030: | train_loss: 0.066: | valid_loss: 0.114\n",
      "EPOCH: 031: | train_loss: 0.063: | valid_loss: 0.110\n",
      "EPOCH: 032: | train_loss: 0.061: | valid_loss: 0.120\n",
      "EPOCH: 033: | train_loss: 0.061: | valid_loss: 0.150\n",
      "EPOCH: 034: | train_loss: 0.061: | valid_loss: 0.101\n",
      "EPOCH: 035: | train_loss: 0.059: | valid_loss: 0.129\n",
      "EPOCH: 036: | train_loss: 0.058: | valid_loss: 0.099\n",
      "EPOCH: 037: | train_loss: 0.055: | valid_loss: 0.094\n",
      "EPOCH: 038: | train_loss: 0.054: | valid_loss: 0.091\n",
      "EPOCH: 039: | train_loss: 0.055: | valid_loss: 0.092\n",
      "EPOCH: 040: | train_loss: 0.054: | valid_loss: 0.087\n",
      "EPOCH: 041: | train_loss: 0.050: | valid_loss: 0.090\n",
      "EPOCH: 042: | train_loss: 0.050: | valid_loss: 0.112\n",
      "EPOCH: 043: | train_loss: 0.051: | valid_loss: 0.089\n",
      "EPOCH: 044: | train_loss: 0.048: | valid_loss: 0.076\n",
      "EPOCH: 045: | train_loss: 0.046: | valid_loss: 0.083\n",
      "EPOCH: 046: | train_loss: 0.043: | valid_loss: 0.076\n",
      "EPOCH: 047: | train_loss: 0.046: | valid_loss: 0.075\n",
      "EPOCH: 048: | train_loss: 0.041: | valid_loss: 0.076\n",
      "EPOCH: 049: | train_loss: 0.042: | valid_loss: 0.076\n",
      "EPOCH: 050: | train_loss: 0.038: | valid_loss: 0.080\n",
      "EPOCH: 051: | train_loss: 0.033: | valid_loss: 0.072\n",
      "EPOCH: 052: | train_loss: 0.033: | valid_loss: 0.073\n",
      "EPOCH: 053: | train_loss: 0.031: | valid_loss: 0.067\n",
      "EPOCH: 054: | train_loss: 0.031: | valid_loss: 0.070\n",
      "EPOCH: 055: | train_loss: 0.030: | valid_loss: 0.065\n",
      "EPOCH: 056: | train_loss: 0.026: | valid_loss: 0.064\n",
      "EPOCH: 057: | train_loss: 0.023: | valid_loss: 0.063\n",
      "EPOCH: 058: | train_loss: 0.023: | valid_loss: 0.064\n",
      "EPOCH: 059: | train_loss: 0.020: | valid_loss: 0.066\n",
      "EPOCH: 060: | train_loss: 0.019: | valid_loss: 0.065\n",
      "EPOCH: 061: | train_loss: 0.018: | valid_loss: 0.067\n",
      "EPOCH: 062: | train_loss: 0.018: | valid_loss: 0.064\n",
      "EPOCH: 063: | train_loss: 0.017: | valid_loss: 0.061\n",
      "EPOCH: 064: | train_loss: 0.016: | valid_loss: 0.064\n",
      "EPOCH: 065: | train_loss: 0.015: | valid_loss: 0.062\n",
      "EPOCH: 066: | train_loss: 0.014: | valid_loss: 0.062\n",
      "EPOCH: 067: | train_loss: 0.013: | valid_loss: 0.063\n",
      "EPOCH: 068: | train_loss: 0.012: | valid_loss: 0.062\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.060\n",
      "EPOCH: 070: | train_loss: 0.011: | valid_loss: 0.062\n",
      "EPOCH: 071: | train_loss: 0.010: | valid_loss: 0.061\n",
      "EPOCH: 072: | train_loss: 0.010: | valid_loss: 0.062\n",
      "EPOCH: 073: | train_loss: 0.010: | valid_loss: 0.062\n",
      "EPOCH: 074: | train_loss: 0.010: | valid_loss: 0.062\n",
      "<BEST LOSS> EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.060\n",
      "CV cross entropy:  0.06023035423710511\n",
      "CV accuracy:  0.89368\n",
      "CPU times: user 5h 10min 3s, sys: 9.2 s, total: 5h 10min 13s\n",
      "Wall time: 5h 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score, oof, predictions = Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.96020186e-07, 3.88856279e-07, 2.25873191e-06, 6.76952823e-07,\n",
       "       9.99995947e-01, 7.34449395e-06, 1.00855527e-06, 9.72782709e-06,\n",
       "       2.96100069e-07, 8.43104942e-07])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999959468841553"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof[3][np.argmax(oof[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(oof[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTarget.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= np.zeros((trainTarget.shape[0],))\n",
    "for i in range(trainTarget.shape[0]):\n",
    "    y_pred[i] = np.argmax(oof[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 9., 9., ..., 9., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "  \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"Pytorch\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#param_space = {'hidden_size1': 512, \n",
    "#               'hidden_size2': 512, \n",
    "#               'dropOutRate1': 0.20393004966355735, \n",
    "#               'dropOutRate2': 0.39170486751620137,\n",
    "#               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "#               'leakyReluSlope': hp.uniform('leakyReluSlope', 1e-3, 1e-1),\n",
    "#              }\n",
    "#\n",
    "#trials = Trials()\n",
    "#\n",
    "#hopt = fmin(fn = HOptExec, \n",
    "#            space = param_space, \n",
    "#            algo = tpe.suggest, \n",
    "#            max_evals = 15, \n",
    "#            #timeout = 8.9 * 60 * 60, \n",
    "#            trials = trials, \n",
    "#           )\n",
    "#\n",
    "#print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
