{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from skimage import exposure, io\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tidalUtl.PrpUtl as prp\n",
    "import tidalUtl.EdaUtl as eda\n",
    "import tidalUtl.Scheduler as sch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet \n",
    "\n",
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ver1__<br>\n",
    "baseline：CV cross entropy 0.102：CV accuracy 0.802<br>\n",
    "__ver2__<br>\n",
    "IAASharpen：CV cross entropy 0.0903：CV accuracy 0.823<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"/home/tidal/ML_Data/CIFAR10/cifar-10-python/cifar-10-batches-py\"\n",
    "OUTPUT = \"/home/tidal/ML_Data/CIFAR10/output\"\n",
    "\n",
    "SUBMIT = OUTPUT + \"/submittion/\"\n",
    "SAVEMODEL = OUTPUT + \"/model/Pytorch/\"\n",
    "SAVEOOF = OUTPUT + \"/OOF/Pytorch/\"\n",
    "SAVEPLOT = OUTPUT + \"/plot_history/\"\n",
    "\n",
    "#ARCH = EfficientNet.from_pretrained('efficientnet-b1') \n",
    "\n",
    "# RUN\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 75\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 50\n",
    "EARLY_STOP = False\n",
    "AUGMENT_PRB = 1\n",
    "IMG_VSL_FLG_TRAIN = True\n",
    "IMG_VSL_FLG_VALID = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "metaData = unpickle(INPUT + '/batches.meta')\n",
    "batch1 = unpickle(INPUT + '/data_batch_1')\n",
    "batch2 = unpickle(INPUT + '/data_batch_2')\n",
    "batch3 = unpickle(INPUT + '/data_batch_3')\n",
    "batch4 = unpickle(INPUT + '/data_batch_4')\n",
    "batch5 = unpickle(INPUT + '/data_batch_5')\n",
    "testBatch = unpickle(INPUT + '/test_batch')\n",
    "\n",
    "#trainは分割されていたのを一つに結合(この時点ではまだseries)\n",
    "trainFeature = np.concatenate([batch1[b'data'], \n",
    "                               batch2[b'data'],\n",
    "                               batch3[b'data'],\n",
    "                               batch4[b'data'],\n",
    "                               batch5[b'data'],])\n",
    "testFeature = testBatch[b'data']\n",
    "\n",
    "trainTarget = np.concatenate([batch1[b'labels'], \n",
    "                               batch2[b'labels'],\n",
    "                               batch3[b'labels'],\n",
    "                               batch4[b'labels'],\n",
    "                               batch5[b'labels'],])\n",
    "testTarget = np.array(testBatch[b'labels'])\n",
    "\n",
    "\n",
    "#pandasとして扱う。\n",
    "trainFeature = pd.DataFrame(trainFeature)\n",
    "trainTarget = pd.Series(trainTarget)\n",
    "testFeature = pd.DataFrame(testFeature)\n",
    "testTarget = pd.Series(testTarget)\n",
    "\n",
    "#targetのカラム\n",
    "tarClmn = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed固定\n",
    "def seed_everything(seed=42):\n",
    "    #data取得についてのランダム性固定\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #cudnnによる演算の安定化(評価値の安定)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    #os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter\n",
    "param_space = {'hidden_size1': 512, \n",
    "               'hidden_size2': 512, \n",
    "               'dropOutRate1': 0.20393004966355735, \n",
    "               'dropOutRate2': 0.39170486751620137,\n",
    "               'leakyReluSlope': 0.01973893854348531,\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: In & Out Type is DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train,testにターゲット値も連結__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Collecting(trainFeature, testFeature, trainTarget):\n",
    "    #targetを結合\n",
    "    trainFeature = pd.concat([trainFeature, trainTarget], axis=1)\n",
    "    #test側のtargetは0で初期化しておく\n",
    "    testTarTmp = pd.DataFrame(np.zeros((testFeature.shape[0],trainTarget.shape[1]),dtype='uint8'), columns=tarClmn)\n",
    "    testFeature = pd.concat([testFeature, testTarTmp], axis=1)\n",
    "    \n",
    "    \n",
    "    return trainFeature, testFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(param, trainFeature, testFeature, trainTarget):\n",
    "    \n",
    "    #targetのデータフレーム作成（列名も付与）(one-hot化しておく)\n",
    "    targetOH = pd.get_dummies(trainTarget)\n",
    "    targetOH.columns = tarClmn\n",
    "    \n",
    "    #train,testにターゲット値を連結。\n",
    "    train, test = Collecting(trainFeature, testFeature, targetOH)\n",
    "    \n",
    "    return train, test, targetOH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 937 ms, sys: 0 ns, total: 937 ms\n",
      "Wall time: 936 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  airplane  \\\n",
       "0   59   43   50   68   98  119  139  145  149  149  ...         0   \n",
       "1  154  126  105  102  125  155  172  180  142  111  ...         0   \n",
       "2  255  253  253  253  253  253  253  253  253  253  ...         0   \n",
       "3   28   37   38   42   44   40   40   24   32   43  ...         0   \n",
       "4  170  168  177  183  181  177  181  184  189  189  ...         0   \n",
       "\n",
       "   automobile  bird  cat  deer  dog  frog  horse  ship  truck  \n",
       "0           0     0    0     0    0     1      0     0      0  \n",
       "1           0     0    0     0    0     0      0     0      1  \n",
       "2           0     0    0     0    0     0      0     0      1  \n",
       "3           0     0    0     1    0     0      0     0      0  \n",
       "4           1     0    0     0    0     0      0     0      0  \n",
       "\n",
       "[5 rows x 3082 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>162</td>\n",
       "      <td>159</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>139</td>\n",
       "      <td>132</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>193</td>\n",
       "      <td>199</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>167</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>177</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>166</td>\n",
       "      <td>170</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  airplane  \\\n",
       "0  158  159  165  166  160  156  162  159  158  159  ...         0   \n",
       "1  235  231  232  232  232  232  232  232  232  232  ...         0   \n",
       "2  158  158  139  132  166  182  187  193  199  205  ...         0   \n",
       "3  155  167  176  190  177  166  168  166  170  179  ...         0   \n",
       "4   65   70   48   30   23   40   44   45   45   40  ...         0   \n",
       "\n",
       "   automobile  bird  cat  deer  dog  frog  horse  ship  truck  \n",
       "0           0     0    0     0    0     0      0     0      0  \n",
       "1           0     0    0     0    0     0      0     0      0  \n",
       "2           0     0    0     0    0     0      0     0      0  \n",
       "3           0     0    0     0    0     0      0     0      0  \n",
       "4           0     0    0     0    0     0      0     0      0  \n",
       "\n",
       "[5 rows x 3082 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
       "0         0           0     0    0     0    0     1      0     0      0\n",
       "1         0           0     0    0     0    0     0      0     0      1\n",
       "2         0           0     0    0     0    0     0      0     0      1\n",
       "3         0           0     0    0     1    0     0      0     0      0\n",
       "4         0           1     0    0     0    0     0      0     0      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50000, 3082)\n",
      "Test: (10000, 3082)\n",
      "Target: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \"+ str(trainVsl.shape))\n",
    "print(\"Test: \"+ str(testVsl.shape))\n",
    "print(\"Target: \"+ str(targetVsl.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainVsl, testVsl, targetVsl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config about Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configは辞書化しておく。\n",
    "def Config_about_Fitting(train, test, target, folds):\n",
    "    confFitting = {}\n",
    "    \n",
    "    #Fitするときに\"y\"として使う列の列名配列\n",
    "    confFitting[\"target_cols\"] = target.columns.values.tolist()\n",
    "    #Fitするときに\"X\"として使う列の列名配列\n",
    "    #kfold, id等はここで削除。\n",
    "    feature_cols = [c for c in folds.columns if c not in confFitting[\"target_cols\"]]\n",
    "    confFitting[\"feature_cols\"] = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "    #特徴量、ターゲットのサイズ\n",
    "    confFitting[\"num_features\"]=len(confFitting[\"feature_cols\"])\n",
    "    confFitting[\"num_targets\"]=len(confFitting[\"target_cols\"])\n",
    "    \n",
    "    return confFitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_folds(train, target):\n",
    "    folds = train.copy()\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    for f, (t_idx, v_idx) in enumerate(skf.split(X=train, y=trainTarget)):\n",
    "        folds.loc[v_idx, 'kfold'] = int(f)\n",
    "    \n",
    "    folds['kfold'] = folds['kfold'].astype(int)\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 954 ms, sys: 43.9 ms, total: 997 ms\n",
      "Wall time: 999 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  automobile  bird  \\\n",
       "0   59   43   50   68   98  119  139  145  149  149  ...           0     0   \n",
       "1  154  126  105  102  125  155  172  180  142  111  ...           0     0   \n",
       "2  255  253  253  253  253  253  253  253  253  253  ...           0     0   \n",
       "3   28   37   38   42   44   40   40   24   32   43  ...           0     0   \n",
       "4  170  168  177  183  181  177  181  184  189  189  ...           1     0   \n",
       "\n",
       "   cat  deer  dog  frog  horse  ship  truck  kfold  \n",
       "0    0     0    0     1      0     0      0      0  \n",
       "1    0     0    0     0      0     0      1      0  \n",
       "2    0     0    0     0      0     0      1      0  \n",
       "3    0     1    0     0      0     0      0      0  \n",
       "4    0     0    0     0      0     0      0      0  \n",
       "\n",
       "[5 rows x 3083 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Preprocessing Data\n",
    "trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)\n",
    "#CV folds\n",
    "foldsVsl = CV_folds(trainVsl, targetVsl)\n",
    "\n",
    "foldsVsl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainVsl, testVsl, targetVsl, foldsVsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train,Valid用のデータクラス\n",
    "class TrainDataset:\n",
    "    def __init__(self, features, targets, p: float = 0.5, transform=None):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        #1列のデータを画像としての形に整形\n",
    "        self.features = self.features.reshape(self.features.shape[0], 3, 32, 32).astype(\"uint8\")\n",
    "        #augmentation\n",
    "        self.transform = transform\n",
    "        self.p = p #transformの使用有無の判断に使用\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx, :]\n",
    "        \n",
    "        if self.transform:\n",
    "            if random.random() < self.p: #pの値を大きくするほどtransformの使用率が上がる。\n",
    "                augmented = self.transform(image=x)\n",
    "                x = augmented['image']\n",
    "                del augmented\n",
    "                        \n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : torch.tensor(x, dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class ValidDataset:\n",
    "    def __init__(self, features, targets, p: float = 0.5, transform=None):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        #1列のデータを画像としての形に整形\n",
    "        self.features = self.features.reshape(self.features.shape[0], 3, 32, 32).astype(\"uint8\")\n",
    "        #augmentation\n",
    "        self.transform = transform\n",
    "        self.p = p #transformの使用有無の判断に使用\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx, :]\n",
    "        \n",
    "        if self.transform:\n",
    "            if random.random() < self.p: #pの値を大きくするほどtransformの使用率が上がる。\n",
    "                augmented = self.transform(image=x)\n",
    "                x = augmented['image']\n",
    "                del augmented\n",
    "                        \n",
    "        #torch.DataLoaderに入れるための形式\n",
    "        dct = {\n",
    "            'x' : torch.tensor(x, dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "#Test用のデータクラス\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            #torch.DataLoaderに入れるための形式\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation():\n",
    "    train_transform = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_TTA():\n",
    "    transform1 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    transform2 = [\n",
    "        albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        #albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    transform3 = [\n",
    "        #albu.HorizontalFlip(p=1),\n",
    "        #albu.VerticalFlip(p=1),\n",
    "        albu.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=1),\n",
    "        #albu.CenterCrop(height=24, width=24, p=1.0),\n",
    "        #albu.IAASharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1),\n",
    "        #albu.Normalize(mean=(0,0,0), std=(1,1,1), max_pixel_value = 255.0, p=1.0),\n",
    "    ]\n",
    "    \n",
    "    transformsCompo = [\n",
    "        albu.Compose(train_transform1),\n",
    "        albu.Compose(train_transform2),\n",
    "        albu.Compose(train_transform3),\n",
    "                      ]\n",
    "    \n",
    "    return transformsCompo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ここを有効にすると何故か本番で違う挙動をするのでtest時以外はコメントアウトしておくこと ##############\n",
    "#transformsVsl = get_augmentation()\n",
    "#\n",
    "#trainVsl, testVsl, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)\n",
    "#foldsVsl = CV_folds(trainVsl, targetVsl)\n",
    "#confFitting = Config_about_Fitting(trainVsl, testVsl, targetVsl, foldsVsl)\n",
    "#imgOrg = foldsVsl[confFitting[\"feature_cols\"]].values[0]\n",
    "#imgOrg = imgOrg.reshape(3, 32, 32).transpose(1, 2, 0).astype(\"uint8\")\n",
    "#\n",
    "#imgTrs = imgOrg.copy()\n",
    "#augmented = transformsVsl(image=imgTrs)\n",
    "#del transformsVsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.axis('off')\n",
    "#plt.imshow(imgOrg)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.axis('off')\n",
    "#plt.imshow(augmented['image'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "#nn.BCEWithLogitsLoss()\n",
    "\n",
    "#class LabelSmoothingCrossEntropy(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "#    def forward(self, x, target, smoothing=0.001):\n",
    "#        confidence = 1. - smoothing\n",
    "#        logprobs = F.log_softmax(x, dim=-1)\n",
    "#        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n",
    "#        smooth_loss = -logprobs.mean(dim=-1)\n",
    "#        loss = confidence * bcs_loss + smoothing * smooth_loss\n",
    "#        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "#nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func: Fitting, Evaluation, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    global IMG_VSL_FLG_TRAIN\n",
    "    \n",
    "    for data in dataloader:\n",
    "        #imageの可視化(最初のデータだけ)\n",
    "        if IMG_VSL_FLG_TRAIN:\n",
    "            img = data['x'][0].detach().cpu().numpy().transpose(1, 2, 0).astype(\"uint8\").copy()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            del img\n",
    "            IMG_VSL_FLG_TRAIN = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    global IMG_VSL_FLG_VALID\n",
    "    \n",
    "    for data in dataloader:\n",
    "        #imageの可視化(最初のデータだけ)\n",
    "        if IMG_VSL_FLG_VALID:\n",
    "            img = data['x'][0].detach().cpu().numpy().transpose(1, 2, 0).astype(\"uint8\").copy()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            del img\n",
    "            IMG_VSL_FLG_VALID = False\n",
    "        \n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 3, 1, 1)\n",
    "x.shape\n",
    "x.view(-1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, param):\n",
    "        super(Model, self).__init__()\n",
    "        #-------------------前準備---------------------------------------------------------------------\n",
    "        self.layersCompo = lambda in_ch, out_ch: [torch.nn.Conv2d(in_ch,  # チャネル入力（色の部分）\n",
    "                                                            out_ch,  # チャンネル出力\n",
    "                                                            3,       # カーネルサイズ(フィルタサイズ)\n",
    "                                                            1,       # ストライド (デフォルトは1)\n",
    "                                                            1,       # パディング (デフォルトは0)\n",
    "                                                            ), \n",
    "                                                  nn.BatchNorm2d(out_ch),\n",
    "                                                  nn.ReLU(),\n",
    "                                                  nn.Dropout(p=0.3)]\n",
    "        \n",
    "        layersList = []\n",
    "        \n",
    "        layersList.extend(self.layersCompo(3, 64))\n",
    "        layersList.extend(self.layersCompo(64, 64))\n",
    "        layersList.extend(self.layersCompo(64, 64))\n",
    "        layersList.append(torch.nn.AvgPool2d(2)) # カーネルサイズ\n",
    "        \n",
    "        layersList.extend(self.layersCompo(64, 128))\n",
    "        layersList.extend(self.layersCompo(128, 128))\n",
    "        layersList.extend(self.layersCompo(128, 128))\n",
    "        layersList.append(torch.nn.AvgPool2d(2)) # カーネルサイズ\n",
    "\n",
    "        layersList.extend(self.layersCompo(128, 256))\n",
    "        layersList.extend(self.layersCompo(256, 256))\n",
    "        layersList.extend(self.layersCompo(256, 256))\n",
    "        \n",
    "        \n",
    "        #------------------モデル--------------------------------------------------------------------------\n",
    "        self.layers = nn.ModuleList(layersList) \n",
    "        #F.avg_pool2d(x, kernel_size=x.size()[2:]) #Grobal average pooling　（画像面ごとにまとめる）\n",
    "        \n",
    "        self.dense1 = nn.Linear(256, num_targets)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            #print(x.shape)\n",
    "            x = self.layers[i](x)\n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.view(-1,256)#[512,256,1,1]->[512,256]\n",
    "        #print(x.shape)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(confFitting, Tester, Plotting, fold, seed, param,\n",
    "                 folds, train, test, target):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = folds\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[confFitting[\"feature_cols\"]].values, train_df[confFitting[\"target_cols\"]].values\n",
    "    x_valid, y_valid =  valid_df[confFitting[\"feature_cols\"]].values, valid_df[confFitting[\"target_cols\"]].values\n",
    "    \n",
    "    #aumentation\n",
    "    transforms = get_augmentation()\n",
    "    \n",
    "    train_dataset = TrainDataset(x_train, y_train, AUGMENT_PRB, transforms)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid, AUGMENT_PRB, transforms)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        #arch=ARCH,\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    #scheduler = sch.CosineAnnealingWarmupRestarts(optimizer,\n",
    "    #                                              first_cycle_steps=200,\n",
    "    #                                              cycle_mult=1.0,\n",
    "    #                                              max_lr=0.01,\n",
    "    #                                              min_lr=0.0001,\n",
    "    #                                              warmup_steps=50,\n",
    "    #                                              gamma=0.5)\n",
    "    \n",
    "    ##### 評価関数 ######\n",
    "    train_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    valid_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.shape[1]))\n",
    "    best_loss = np.inf\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'valid_loss': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, train_loss_fn, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, valid_loss_fn, validloader, DEVICE)\n",
    "        if Tester:\n",
    "            print(\"EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(epoch, train_loss, valid_loss))\n",
    "                \n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_epoch = epoch\n",
    "            best_train_loss = train_loss\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                if Tester:\n",
    "                    print('Early stopping. Best Val loss: {:.3f}'.format(best_loss))\n",
    "                break\n",
    "            \n",
    "    print(\"<BEST LOSS> EPOCH: {:03}: | train_loss: {:.3f}: | valid_loss: {:.3f}\".format(best_epoch, best_train_loss, best_loss))\n",
    "    \n",
    "    #Visuarization\n",
    "    if Plotting:\n",
    "        plt.plot(range(1, len(history['train_loss']) + 1), history['train_loss'], label='train_loss')\n",
    "        plt.plot(range(1, len(history['valid_loss']) + 1), history['valid_loss'], label='valid_loss')\n",
    "        plt.title(f'Seed{seed} Fold{fold} LOSS VISUARIZATION')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{SAVEPLOT}Seed{seed}_Fold{fold}_history.png')\n",
    "        plt.close()\n",
    "    \n",
    "    del history\n",
    "    \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    #x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    #testdataset = TestDataset(x_test)\n",
    "    #testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #\n",
    "    #model = Model(\n",
    "    #    num_features=confFitting[\"num_features\"],\n",
    "    #    num_targets=confFitting[\"num_targets\"],\n",
    "    #    arch=ARCH,\n",
    "    #    param=param\n",
    "    #)\n",
    "    #\n",
    "    #model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    #model.to(DEVICE)\n",
    "    #\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    #predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(Tester, Plotting, NFOLDS, seed, param,\n",
    "              folds, train, test, target, confFitting):\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        oof_, pred_ = run_training(confFitting, Tester, Plotting, fold, seed, param,\n",
    "                                   folds, train, test, target)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def CV_Evaluation(confFitting, oof, target):\n",
    "    score = []\n",
    "    \n",
    "    #cross entropy\n",
    "    y_true_OH = target[confFitting[\"target_cols\"]].values\n",
    "    y_pred_proba = oof\n",
    "    \n",
    "    score_logloss = 0\n",
    "    for i in range(confFitting[\"num_targets\"]):\n",
    "        score_ = log_loss(y_true_OH[:, i], y_pred_proba[:, i]) #問題の評価指標によって変わる。\n",
    "        score_logloss += score_ / target.shape[1]\n",
    "        \n",
    "    print(\"CV cross entropy: \", score_logloss)\n",
    "    score.append(score_logloss)\n",
    "    \n",
    "    \n",
    "    #accuracy\n",
    "    score_accuracy = 0\n",
    "    y_true = trainTarget.values\n",
    "    y_pred= np.zeros((trainTarget.shape[0],))\n",
    "    for i in range(trainTarget.shape[0]):\n",
    "        #pred_proba->predに変形\n",
    "        y_pred[i] = np.argmax(oof[i])\n",
    "    \n",
    "    score_accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"CV accuracy: \", score_accuracy)\n",
    "    score.append(score_accuracy)\n",
    "    \n",
    "    \n",
    "    #OOF save\n",
    "    np.save(SAVEOOF + 'oof', y_pred_proba)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特になし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submit(confFitting, predictions, test):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Exec(param):\n",
    "    \n",
    "    #Tester(True/False)\n",
    "    Tester = True\n",
    "    \n",
    "    #Plot(True/False)\n",
    "    Plotting = True\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTarget)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [42]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, Plotting, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score, oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ SEED 42 ~~~~~~~~~~~~~~~~~~~~\n",
      "==================== Fold 0 ====================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 000: | train_loss: 0.615: | valid_loss: 0.441\n",
      "EPOCH: 001: | train_loss: 0.314: | valid_loss: 0.286\n",
      "EPOCH: 002: | train_loss: 0.227: | valid_loss: 0.482\n",
      "EPOCH: 003: | train_loss: 0.190: | valid_loss: 0.324\n",
      "EPOCH: 004: | train_loss: 0.173: | valid_loss: 0.321\n",
      "EPOCH: 005: | train_loss: 0.163: | valid_loss: 0.545\n",
      "EPOCH: 006: | train_loss: 0.148: | valid_loss: 0.253\n",
      "EPOCH: 007: | train_loss: 0.137: | valid_loss: 0.169\n",
      "EPOCH: 008: | train_loss: 0.124: | valid_loss: 0.225\n",
      "EPOCH: 009: | train_loss: 0.122: | valid_loss: 0.164\n",
      "EPOCH: 010: | train_loss: 0.112: | valid_loss: 0.203\n",
      "EPOCH: 011: | train_loss: 0.105: | valid_loss: 0.160\n",
      "EPOCH: 012: | train_loss: 0.101: | valid_loss: 0.221\n",
      "EPOCH: 013: | train_loss: 0.095: | valid_loss: 0.166\n",
      "EPOCH: 014: | train_loss: 0.092: | valid_loss: 0.217\n",
      "EPOCH: 015: | train_loss: 0.092: | valid_loss: 0.130\n",
      "EPOCH: 016: | train_loss: 0.086: | valid_loss: 0.142\n",
      "EPOCH: 017: | train_loss: 0.084: | valid_loss: 0.141\n",
      "EPOCH: 018: | train_loss: 0.080: | valid_loss: 0.180\n",
      "EPOCH: 019: | train_loss: 0.085: | valid_loss: 0.108\n",
      "EPOCH: 020: | train_loss: 0.081: | valid_loss: 0.117\n",
      "EPOCH: 021: | train_loss: 0.077: | valid_loss: 0.106\n",
      "EPOCH: 022: | train_loss: 0.075: | valid_loss: 0.102\n",
      "EPOCH: 023: | train_loss: 0.072: | valid_loss: 0.136\n",
      "EPOCH: 024: | train_loss: 0.071: | valid_loss: 0.130\n",
      "EPOCH: 025: | train_loss: 0.075: | valid_loss: 0.114\n",
      "EPOCH: 026: | train_loss: 0.078: | valid_loss: 0.096\n",
      "EPOCH: 027: | train_loss: 0.070: | valid_loss: 0.097\n",
      "EPOCH: 028: | train_loss: 0.068: | valid_loss: 0.100\n",
      "EPOCH: 029: | train_loss: 0.070: | valid_loss: 0.224\n",
      "EPOCH: 030: | train_loss: 0.078: | valid_loss: 0.106\n",
      "EPOCH: 031: | train_loss: 0.063: | valid_loss: 0.078\n",
      "EPOCH: 032: | train_loss: 0.061: | valid_loss: 0.109\n",
      "EPOCH: 033: | train_loss: 0.063: | valid_loss: 0.074\n",
      "EPOCH: 034: | train_loss: 0.056: | valid_loss: 0.092\n",
      "EPOCH: 035: | train_loss: 0.056: | valid_loss: 0.106\n",
      "EPOCH: 036: | train_loss: 0.058: | valid_loss: 0.092\n",
      "EPOCH: 037: | train_loss: 0.053: | valid_loss: 0.092\n",
      "EPOCH: 038: | train_loss: 0.052: | valid_loss: 0.081\n",
      "EPOCH: 039: | train_loss: 0.052: | valid_loss: 0.075\n",
      "EPOCH: 040: | train_loss: 0.055: | valid_loss: 0.079\n",
      "EPOCH: 041: | train_loss: 0.051: | valid_loss: 0.071\n",
      "EPOCH: 042: | train_loss: 0.045: | valid_loss: 0.074\n",
      "EPOCH: 043: | train_loss: 0.046: | valid_loss: 0.068\n",
      "EPOCH: 044: | train_loss: 0.051: | valid_loss: 0.074\n",
      "EPOCH: 045: | train_loss: 0.044: | valid_loss: 0.071\n",
      "EPOCH: 046: | train_loss: 0.041: | valid_loss: 0.066\n",
      "EPOCH: 047: | train_loss: 0.043: | valid_loss: 0.065\n",
      "EPOCH: 048: | train_loss: 0.042: | valid_loss: 0.060\n",
      "EPOCH: 049: | train_loss: 0.037: | valid_loss: 0.061\n",
      "EPOCH: 050: | train_loss: 0.033: | valid_loss: 0.061\n",
      "EPOCH: 051: | train_loss: 0.034: | valid_loss: 0.061\n",
      "EPOCH: 052: | train_loss: 0.033: | valid_loss: 0.058\n",
      "EPOCH: 053: | train_loss: 0.028: | valid_loss: 0.058\n",
      "EPOCH: 054: | train_loss: 0.025: | valid_loss: 0.061\n",
      "EPOCH: 055: | train_loss: 0.025: | valid_loss: 0.061\n",
      "EPOCH: 056: | train_loss: 0.024: | valid_loss: 0.062\n",
      "EPOCH: 057: | train_loss: 0.025: | valid_loss: 0.056\n",
      "EPOCH: 058: | train_loss: 0.021: | valid_loss: 0.061\n",
      "EPOCH: 059: | train_loss: 0.020: | valid_loss: 0.058\n",
      "EPOCH: 060: | train_loss: 0.018: | valid_loss: 0.057\n",
      "EPOCH: 061: | train_loss: 0.018: | valid_loss: 0.059\n",
      "EPOCH: 062: | train_loss: 0.017: | valid_loss: 0.056\n",
      "EPOCH: 063: | train_loss: 0.017: | valid_loss: 0.057\n",
      "EPOCH: 064: | train_loss: 0.015: | valid_loss: 0.056\n",
      "EPOCH: 065: | train_loss: 0.014: | valid_loss: 0.056\n",
      "EPOCH: 066: | train_loss: 0.013: | valid_loss: 0.055\n",
      "EPOCH: 067: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 068: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 070: | train_loss: 0.011: | valid_loss: 0.057\n",
      "EPOCH: 071: | train_loss: 0.011: | valid_loss: 0.056\n",
      "EPOCH: 072: | train_loss: 0.011: | valid_loss: 0.056\n",
      "EPOCH: 073: | train_loss: 0.011: | valid_loss: 0.056\n",
      "EPOCH: 074: | train_loss: 0.011: | valid_loss: 0.055\n",
      "<BEST LOSS> EPOCH: 066: | train_loss: 0.013: | valid_loss: 0.055\n",
      "==================== Fold 1 ====================\n",
      "EPOCH: 000: | train_loss: 0.615: | valid_loss: 0.448\n",
      "EPOCH: 001: | train_loss: 0.314: | valid_loss: 0.325\n",
      "EPOCH: 002: | train_loss: 0.230: | valid_loss: 0.250\n",
      "EPOCH: 003: | train_loss: 0.194: | valid_loss: 0.284\n",
      "EPOCH: 004: | train_loss: 0.178: | valid_loss: 0.305\n",
      "EPOCH: 005: | train_loss: 0.164: | valid_loss: 0.291\n",
      "EPOCH: 006: | train_loss: 0.151: | valid_loss: 0.244\n",
      "EPOCH: 007: | train_loss: 0.139: | valid_loss: 0.313\n",
      "EPOCH: 008: | train_loss: 0.127: | valid_loss: 0.224\n",
      "EPOCH: 009: | train_loss: 0.124: | valid_loss: 0.214\n",
      "EPOCH: 010: | train_loss: 0.112: | valid_loss: 0.203\n",
      "EPOCH: 011: | train_loss: 0.108: | valid_loss: 0.155\n",
      "EPOCH: 012: | train_loss: 0.104: | valid_loss: 0.160\n",
      "EPOCH: 013: | train_loss: 0.097: | valid_loss: 0.210\n",
      "EPOCH: 014: | train_loss: 0.096: | valid_loss: 0.129\n",
      "EPOCH: 015: | train_loss: 0.089: | valid_loss: 0.152\n",
      "EPOCH: 016: | train_loss: 0.091: | valid_loss: 0.165\n",
      "EPOCH: 017: | train_loss: 0.087: | valid_loss: 0.120\n",
      "EPOCH: 018: | train_loss: 0.081: | valid_loss: 0.121\n",
      "EPOCH: 019: | train_loss: 0.083: | valid_loss: 0.230\n",
      "EPOCH: 020: | train_loss: 0.087: | valid_loss: 0.171\n",
      "EPOCH: 021: | train_loss: 0.082: | valid_loss: 0.165\n",
      "EPOCH: 022: | train_loss: 0.077: | valid_loss: 0.120\n",
      "EPOCH: 023: | train_loss: 0.075: | valid_loss: 0.161\n",
      "EPOCH: 024: | train_loss: 0.073: | valid_loss: 0.112\n",
      "EPOCH: 025: | train_loss: 0.074: | valid_loss: 0.134\n",
      "EPOCH: 026: | train_loss: 0.075: | valid_loss: 0.127\n",
      "EPOCH: 027: | train_loss: 0.077: | valid_loss: 0.092\n",
      "EPOCH: 028: | train_loss: 0.068: | valid_loss: 0.144\n",
      "EPOCH: 029: | train_loss: 0.072: | valid_loss: 0.224\n",
      "EPOCH: 030: | train_loss: 0.070: | valid_loss: 0.090\n",
      "EPOCH: 031: | train_loss: 0.064: | valid_loss: 0.130\n",
      "EPOCH: 032: | train_loss: 0.063: | valid_loss: 0.086\n",
      "EPOCH: 033: | train_loss: 0.058: | valid_loss: 0.085\n",
      "EPOCH: 034: | train_loss: 0.054: | valid_loss: 0.081\n",
      "EPOCH: 035: | train_loss: 0.057: | valid_loss: 0.102\n",
      "EPOCH: 036: | train_loss: 0.057: | valid_loss: 0.070\n",
      "EPOCH: 037: | train_loss: 0.055: | valid_loss: 0.084\n",
      "EPOCH: 038: | train_loss: 0.052: | valid_loss: 0.086\n",
      "EPOCH: 039: | train_loss: 0.057: | valid_loss: 0.072\n",
      "EPOCH: 040: | train_loss: 0.055: | valid_loss: 0.092\n",
      "EPOCH: 041: | train_loss: 0.052: | valid_loss: 0.074\n",
      "EPOCH: 042: | train_loss: 0.048: | valid_loss: 0.077\n",
      "EPOCH: 043: | train_loss: 0.049: | valid_loss: 0.076\n",
      "EPOCH: 044: | train_loss: 0.053: | valid_loss: 0.066\n",
      "EPOCH: 045: | train_loss: 0.045: | valid_loss: 0.063\n",
      "EPOCH: 046: | train_loss: 0.041: | valid_loss: 0.068\n",
      "EPOCH: 047: | train_loss: 0.042: | valid_loss: 0.064\n",
      "EPOCH: 048: | train_loss: 0.038: | valid_loss: 0.060\n",
      "EPOCH: 049: | train_loss: 0.035: | valid_loss: 0.060\n",
      "EPOCH: 050: | train_loss: 0.035: | valid_loss: 0.076\n",
      "EPOCH: 051: | train_loss: 0.036: | valid_loss: 0.061\n",
      "EPOCH: 052: | train_loss: 0.036: | valid_loss: 0.060\n",
      "EPOCH: 053: | train_loss: 0.030: | valid_loss: 0.059\n",
      "EPOCH: 054: | train_loss: 0.028: | valid_loss: 0.056\n",
      "EPOCH: 055: | train_loss: 0.026: | valid_loss: 0.057\n",
      "EPOCH: 056: | train_loss: 0.029: | valid_loss: 0.062\n",
      "EPOCH: 057: | train_loss: 0.025: | valid_loss: 0.058\n",
      "EPOCH: 058: | train_loss: 0.024: | valid_loss: 0.059\n",
      "EPOCH: 059: | train_loss: 0.022: | valid_loss: 0.058\n",
      "EPOCH: 060: | train_loss: 0.019: | valid_loss: 0.056\n",
      "EPOCH: 061: | train_loss: 0.018: | valid_loss: 0.056\n",
      "EPOCH: 062: | train_loss: 0.017: | valid_loss: 0.055\n",
      "EPOCH: 063: | train_loss: 0.016: | valid_loss: 0.057\n",
      "EPOCH: 064: | train_loss: 0.015: | valid_loss: 0.056\n",
      "EPOCH: 065: | train_loss: 0.014: | valid_loss: 0.056\n",
      "EPOCH: 066: | train_loss: 0.013: | valid_loss: 0.057\n",
      "EPOCH: 067: | train_loss: 0.013: | valid_loss: 0.056\n",
      "EPOCH: 068: | train_loss: 0.013: | valid_loss: 0.057\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 070: | train_loss: 0.012: | valid_loss: 0.057\n",
      "EPOCH: 071: | train_loss: 0.012: | valid_loss: 0.057\n",
      "EPOCH: 072: | train_loss: 0.012: | valid_loss: 0.057\n",
      "EPOCH: 073: | train_loss: 0.011: | valid_loss: 0.056\n",
      "EPOCH: 074: | train_loss: 0.011: | valid_loss: 0.056\n",
      "<BEST LOSS> EPOCH: 062: | train_loss: 0.017: | valid_loss: 0.055\n",
      "==================== Fold 2 ====================\n",
      "EPOCH: 000: | train_loss: 0.615: | valid_loss: 0.466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 001: | train_loss: 0.314: | valid_loss: 0.363\n",
      "EPOCH: 002: | train_loss: 0.232: | valid_loss: 0.297\n",
      "EPOCH: 003: | train_loss: 0.201: | valid_loss: 0.281\n",
      "EPOCH: 004: | train_loss: 0.176: | valid_loss: 0.863\n",
      "EPOCH: 005: | train_loss: 0.164: | valid_loss: 0.580\n",
      "EPOCH: 006: | train_loss: 0.157: | valid_loss: 0.290\n",
      "EPOCH: 007: | train_loss: 0.140: | valid_loss: 0.330\n",
      "EPOCH: 008: | train_loss: 0.132: | valid_loss: 0.218\n",
      "EPOCH: 009: | train_loss: 0.124: | valid_loss: 0.232\n",
      "EPOCH: 010: | train_loss: 0.114: | valid_loss: 0.184\n",
      "EPOCH: 011: | train_loss: 0.108: | valid_loss: 0.155\n",
      "EPOCH: 012: | train_loss: 0.107: | valid_loss: 0.139\n",
      "EPOCH: 013: | train_loss: 0.100: | valid_loss: 0.233\n",
      "EPOCH: 014: | train_loss: 0.096: | valid_loss: 0.177\n",
      "EPOCH: 015: | train_loss: 0.095: | valid_loss: 0.129\n",
      "EPOCH: 016: | train_loss: 0.092: | valid_loss: 0.186\n",
      "EPOCH: 017: | train_loss: 0.092: | valid_loss: 0.151\n",
      "EPOCH: 018: | train_loss: 0.085: | valid_loss: 0.153\n",
      "EPOCH: 019: | train_loss: 0.085: | valid_loss: 0.309\n",
      "EPOCH: 020: | train_loss: 0.087: | valid_loss: 0.180\n",
      "EPOCH: 021: | train_loss: 0.078: | valid_loss: 0.146\n",
      "EPOCH: 022: | train_loss: 0.077: | valid_loss: 0.130\n",
      "EPOCH: 023: | train_loss: 0.075: | valid_loss: 0.144\n",
      "EPOCH: 024: | train_loss: 0.073: | valid_loss: 0.134\n",
      "EPOCH: 025: | train_loss: 0.077: | valid_loss: 0.120\n",
      "EPOCH: 026: | train_loss: 0.076: | valid_loss: 0.191\n",
      "EPOCH: 027: | train_loss: 0.083: | valid_loss: 0.090\n",
      "EPOCH: 028: | train_loss: 0.069: | valid_loss: 0.085\n",
      "EPOCH: 029: | train_loss: 0.069: | valid_loss: 0.112\n",
      "EPOCH: 030: | train_loss: 0.068: | valid_loss: 0.110\n",
      "EPOCH: 031: | train_loss: 0.065: | valid_loss: 0.089\n",
      "EPOCH: 032: | train_loss: 0.064: | valid_loss: 0.079\n",
      "EPOCH: 033: | train_loss: 0.060: | valid_loss: 0.102\n",
      "EPOCH: 034: | train_loss: 0.059: | valid_loss: 0.104\n",
      "EPOCH: 035: | train_loss: 0.055: | valid_loss: 0.087\n",
      "EPOCH: 036: | train_loss: 0.055: | valid_loss: 0.087\n",
      "EPOCH: 037: | train_loss: 0.061: | valid_loss: 0.115\n",
      "EPOCH: 038: | train_loss: 0.056: | valid_loss: 0.081\n",
      "EPOCH: 039: | train_loss: 0.056: | valid_loss: 0.084\n",
      "EPOCH: 040: | train_loss: 0.058: | valid_loss: 0.080\n",
      "EPOCH: 041: | train_loss: 0.052: | valid_loss: 0.069\n",
      "EPOCH: 042: | train_loss: 0.052: | valid_loss: 0.072\n",
      "EPOCH: 043: | train_loss: 0.050: | valid_loss: 0.079\n",
      "EPOCH: 044: | train_loss: 0.052: | valid_loss: 0.070\n",
      "EPOCH: 045: | train_loss: 0.049: | valid_loss: 0.061\n",
      "EPOCH: 046: | train_loss: 0.040: | valid_loss: 0.084\n",
      "EPOCH: 047: | train_loss: 0.048: | valid_loss: 0.064\n",
      "EPOCH: 048: | train_loss: 0.042: | valid_loss: 0.069\n",
      "EPOCH: 049: | train_loss: 0.038: | valid_loss: 0.064\n",
      "EPOCH: 050: | train_loss: 0.035: | valid_loss: 0.060\n",
      "EPOCH: 051: | train_loss: 0.032: | valid_loss: 0.058\n",
      "EPOCH: 052: | train_loss: 0.034: | valid_loss: 0.063\n",
      "EPOCH: 053: | train_loss: 0.031: | valid_loss: 0.058\n",
      "EPOCH: 054: | train_loss: 0.027: | valid_loss: 0.056\n",
      "EPOCH: 055: | train_loss: 0.030: | valid_loss: 0.059\n",
      "EPOCH: 056: | train_loss: 0.028: | valid_loss: 0.062\n",
      "EPOCH: 057: | train_loss: 0.027: | valid_loss: 0.059\n",
      "EPOCH: 058: | train_loss: 0.025: | valid_loss: 0.058\n",
      "EPOCH: 059: | train_loss: 0.023: | valid_loss: 0.056\n",
      "EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.057\n",
      "EPOCH: 061: | train_loss: 0.020: | valid_loss: 0.054\n",
      "EPOCH: 062: | train_loss: 0.019: | valid_loss: 0.055\n",
      "EPOCH: 063: | train_loss: 0.018: | valid_loss: 0.055\n",
      "EPOCH: 064: | train_loss: 0.017: | valid_loss: 0.053\n",
      "EPOCH: 065: | train_loss: 0.016: | valid_loss: 0.056\n",
      "EPOCH: 066: | train_loss: 0.015: | valid_loss: 0.055\n",
      "EPOCH: 067: | train_loss: 0.014: | valid_loss: 0.054\n",
      "EPOCH: 068: | train_loss: 0.014: | valid_loss: 0.054\n",
      "EPOCH: 069: | train_loss: 0.013: | valid_loss: 0.054\n",
      "EPOCH: 070: | train_loss: 0.013: | valid_loss: 0.055\n",
      "EPOCH: 071: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 072: | train_loss: 0.013: | valid_loss: 0.055\n",
      "EPOCH: 073: | train_loss: 0.012: | valid_loss: 0.054\n",
      "EPOCH: 074: | train_loss: 0.012: | valid_loss: 0.054\n",
      "<BEST LOSS> EPOCH: 064: | train_loss: 0.017: | valid_loss: 0.053\n",
      "==================== Fold 3 ====================\n",
      "EPOCH: 000: | train_loss: 0.615: | valid_loss: 0.447\n",
      "EPOCH: 001: | train_loss: 0.313: | valid_loss: 0.373\n",
      "EPOCH: 002: | train_loss: 0.230: | valid_loss: 0.525\n",
      "EPOCH: 003: | train_loss: 0.197: | valid_loss: 0.644\n",
      "EPOCH: 004: | train_loss: 0.180: | valid_loss: 0.341\n",
      "EPOCH: 005: | train_loss: 0.166: | valid_loss: 0.249\n",
      "EPOCH: 006: | train_loss: 0.152: | valid_loss: 0.287\n",
      "EPOCH: 007: | train_loss: 0.141: | valid_loss: 0.345\n",
      "EPOCH: 008: | train_loss: 0.133: | valid_loss: 0.207\n",
      "EPOCH: 009: | train_loss: 0.124: | valid_loss: 0.258\n",
      "EPOCH: 010: | train_loss: 0.117: | valid_loss: 0.235\n",
      "EPOCH: 011: | train_loss: 0.109: | valid_loss: 0.158\n",
      "EPOCH: 012: | train_loss: 0.105: | valid_loss: 0.176\n",
      "EPOCH: 013: | train_loss: 0.101: | valid_loss: 0.207\n",
      "EPOCH: 014: | train_loss: 0.096: | valid_loss: 0.148\n",
      "EPOCH: 015: | train_loss: 0.091: | valid_loss: 0.232\n",
      "EPOCH: 016: | train_loss: 0.090: | valid_loss: 0.128\n",
      "EPOCH: 017: | train_loss: 0.090: | valid_loss: 0.216\n",
      "EPOCH: 018: | train_loss: 0.090: | valid_loss: 0.195\n",
      "EPOCH: 019: | train_loss: 0.083: | valid_loss: 0.275\n",
      "EPOCH: 020: | train_loss: 0.090: | valid_loss: 0.121\n",
      "EPOCH: 021: | train_loss: 0.081: | valid_loss: 0.164\n",
      "EPOCH: 022: | train_loss: 0.075: | valid_loss: 0.101\n",
      "EPOCH: 023: | train_loss: 0.075: | valid_loss: 0.142\n",
      "EPOCH: 024: | train_loss: 0.073: | valid_loss: 0.123\n",
      "EPOCH: 025: | train_loss: 0.073: | valid_loss: 0.121\n",
      "EPOCH: 026: | train_loss: 0.073: | valid_loss: 0.175\n",
      "EPOCH: 027: | train_loss: 0.072: | valid_loss: 0.087\n",
      "EPOCH: 028: | train_loss: 0.068: | valid_loss: 0.105\n",
      "EPOCH: 029: | train_loss: 0.070: | valid_loss: 0.120\n",
      "EPOCH: 030: | train_loss: 0.066: | valid_loss: 0.111\n",
      "EPOCH: 031: | train_loss: 0.066: | valid_loss: 0.093\n",
      "EPOCH: 032: | train_loss: 0.063: | valid_loss: 0.128\n",
      "EPOCH: 033: | train_loss: 0.065: | valid_loss: 0.104\n",
      "EPOCH: 034: | train_loss: 0.056: | valid_loss: 0.077\n",
      "EPOCH: 035: | train_loss: 0.059: | valid_loss: 0.105\n",
      "EPOCH: 036: | train_loss: 0.062: | valid_loss: 0.083\n",
      "EPOCH: 037: | train_loss: 0.053: | valid_loss: 0.092\n",
      "EPOCH: 038: | train_loss: 0.053: | valid_loss: 0.088\n",
      "EPOCH: 039: | train_loss: 0.055: | valid_loss: 0.081\n",
      "EPOCH: 040: | train_loss: 0.057: | valid_loss: 0.087\n",
      "EPOCH: 041: | train_loss: 0.050: | valid_loss: 0.087\n",
      "EPOCH: 042: | train_loss: 0.047: | valid_loss: 0.073\n",
      "EPOCH: 043: | train_loss: 0.050: | valid_loss: 0.072\n",
      "EPOCH: 044: | train_loss: 0.047: | valid_loss: 0.072\n",
      "EPOCH: 045: | train_loss: 0.045: | valid_loss: 0.071\n",
      "EPOCH: 046: | train_loss: 0.043: | valid_loss: 0.071\n",
      "EPOCH: 047: | train_loss: 0.044: | valid_loss: 0.077\n",
      "EPOCH: 048: | train_loss: 0.039: | valid_loss: 0.066\n",
      "EPOCH: 049: | train_loss: 0.040: | valid_loss: 0.066\n",
      "EPOCH: 050: | train_loss: 0.036: | valid_loss: 0.061\n",
      "EPOCH: 051: | train_loss: 0.033: | valid_loss: 0.064\n",
      "EPOCH: 052: | train_loss: 0.031: | valid_loss: 0.061\n",
      "EPOCH: 053: | train_loss: 0.028: | valid_loss: 0.059\n",
      "EPOCH: 054: | train_loss: 0.028: | valid_loss: 0.061\n",
      "EPOCH: 055: | train_loss: 0.026: | valid_loss: 0.062\n",
      "EPOCH: 056: | train_loss: 0.027: | valid_loss: 0.058\n",
      "EPOCH: 057: | train_loss: 0.024: | valid_loss: 0.062\n",
      "EPOCH: 058: | train_loss: 0.024: | valid_loss: 0.056\n",
      "EPOCH: 059: | train_loss: 0.022: | valid_loss: 0.056\n",
      "EPOCH: 060: | train_loss: 0.021: | valid_loss: 0.058\n",
      "EPOCH: 061: | train_loss: 0.019: | valid_loss: 0.058\n",
      "EPOCH: 062: | train_loss: 0.018: | valid_loss: 0.057\n",
      "EPOCH: 063: | train_loss: 0.017: | valid_loss: 0.057\n",
      "EPOCH: 064: | train_loss: 0.016: | valid_loss: 0.059\n",
      "EPOCH: 065: | train_loss: 0.015: | valid_loss: 0.057\n",
      "EPOCH: 066: | train_loss: 0.015: | valid_loss: 0.058\n",
      "EPOCH: 067: | train_loss: 0.014: | valid_loss: 0.056\n",
      "EPOCH: 068: | train_loss: 0.013: | valid_loss: 0.058\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 070: | train_loss: 0.012: | valid_loss: 0.057\n",
      "EPOCH: 071: | train_loss: 0.012: | valid_loss: 0.057\n",
      "EPOCH: 072: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 073: | train_loss: 0.012: | valid_loss: 0.056\n",
      "EPOCH: 074: | train_loss: 0.012: | valid_loss: 0.056\n",
      "<BEST LOSS> EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.056\n",
      "==================== Fold 4 ====================\n",
      "EPOCH: 000: | train_loss: 0.615: | valid_loss: 0.464\n",
      "EPOCH: 001: | train_loss: 0.313: | valid_loss: 0.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 002: | train_loss: 0.231: | valid_loss: 0.268\n",
      "EPOCH: 003: | train_loss: 0.197: | valid_loss: 0.339\n",
      "EPOCH: 004: | train_loss: 0.180: | valid_loss: 0.340\n",
      "EPOCH: 005: | train_loss: 0.164: | valid_loss: 0.289\n",
      "EPOCH: 006: | train_loss: 0.154: | valid_loss: 0.246\n",
      "EPOCH: 007: | train_loss: 0.140: | valid_loss: 0.262\n",
      "EPOCH: 008: | train_loss: 0.128: | valid_loss: 0.352\n",
      "EPOCH: 009: | train_loss: 0.125: | valid_loss: 0.192\n",
      "EPOCH: 010: | train_loss: 0.112: | valid_loss: 0.238\n",
      "EPOCH: 011: | train_loss: 0.106: | valid_loss: 0.166\n",
      "EPOCH: 012: | train_loss: 0.101: | valid_loss: 0.224\n",
      "EPOCH: 013: | train_loss: 0.099: | valid_loss: 0.251\n",
      "EPOCH: 014: | train_loss: 0.099: | valid_loss: 0.161\n",
      "EPOCH: 015: | train_loss: 0.093: | valid_loss: 0.175\n",
      "EPOCH: 016: | train_loss: 0.091: | valid_loss: 0.294\n",
      "EPOCH: 017: | train_loss: 0.089: | valid_loss: 0.306\n",
      "EPOCH: 018: | train_loss: 0.090: | valid_loss: 0.165\n",
      "EPOCH: 019: | train_loss: 0.087: | valid_loss: 0.157\n",
      "EPOCH: 020: | train_loss: 0.084: | valid_loss: 0.205\n",
      "EPOCH: 021: | train_loss: 0.079: | valid_loss: 0.131\n",
      "EPOCH: 022: | train_loss: 0.077: | valid_loss: 0.117\n",
      "EPOCH: 023: | train_loss: 0.074: | valid_loss: 0.112\n",
      "EPOCH: 024: | train_loss: 0.075: | valid_loss: 0.121\n",
      "EPOCH: 025: | train_loss: 0.073: | valid_loss: 0.107\n",
      "EPOCH: 026: | train_loss: 0.071: | valid_loss: 0.094\n",
      "EPOCH: 027: | train_loss: 0.067: | valid_loss: 0.144\n",
      "EPOCH: 028: | train_loss: 0.067: | valid_loss: 0.101\n",
      "EPOCH: 029: | train_loss: 0.068: | valid_loss: 0.090\n",
      "EPOCH: 030: | train_loss: 0.067: | valid_loss: 0.101\n",
      "EPOCH: 031: | train_loss: 0.064: | valid_loss: 0.114\n",
      "EPOCH: 032: | train_loss: 0.064: | valid_loss: 0.081\n",
      "EPOCH: 033: | train_loss: 0.060: | valid_loss: 0.086\n",
      "EPOCH: 034: | train_loss: 0.058: | valid_loss: 0.102\n",
      "EPOCH: 035: | train_loss: 0.057: | valid_loss: 0.086\n",
      "EPOCH: 036: | train_loss: 0.059: | valid_loss: 0.084\n",
      "EPOCH: 037: | train_loss: 0.053: | valid_loss: 0.101\n",
      "EPOCH: 038: | train_loss: 0.052: | valid_loss: 0.075\n",
      "EPOCH: 039: | train_loss: 0.052: | valid_loss: 0.077\n",
      "EPOCH: 040: | train_loss: 0.049: | valid_loss: 0.104\n",
      "EPOCH: 041: | train_loss: 0.051: | valid_loss: 0.081\n",
      "EPOCH: 042: | train_loss: 0.048: | valid_loss: 0.072\n",
      "EPOCH: 043: | train_loss: 0.049: | valid_loss: 0.086\n",
      "EPOCH: 044: | train_loss: 0.046: | valid_loss: 0.063\n",
      "EPOCH: 045: | train_loss: 0.042: | valid_loss: 0.069\n",
      "EPOCH: 046: | train_loss: 0.041: | valid_loss: 0.062\n",
      "EPOCH: 047: | train_loss: 0.041: | valid_loss: 0.078\n",
      "EPOCH: 048: | train_loss: 0.040: | valid_loss: 0.068\n",
      "EPOCH: 049: | train_loss: 0.043: | valid_loss: 0.064\n",
      "EPOCH: 050: | train_loss: 0.039: | valid_loss: 0.057\n",
      "EPOCH: 051: | train_loss: 0.034: | valid_loss: 0.056\n",
      "EPOCH: 052: | train_loss: 0.032: | valid_loss: 0.057\n",
      "EPOCH: 053: | train_loss: 0.028: | valid_loss: 0.058\n",
      "EPOCH: 054: | train_loss: 0.029: | valid_loss: 0.059\n",
      "EPOCH: 055: | train_loss: 0.028: | valid_loss: 0.059\n",
      "EPOCH: 056: | train_loss: 0.028: | valid_loss: 0.059\n",
      "EPOCH: 057: | train_loss: 0.025: | valid_loss: 0.058\n",
      "EPOCH: 058: | train_loss: 0.022: | valid_loss: 0.059\n",
      "EPOCH: 059: | train_loss: 0.021: | valid_loss: 0.058\n",
      "EPOCH: 060: | train_loss: 0.020: | valid_loss: 0.057\n",
      "EPOCH: 061: | train_loss: 0.019: | valid_loss: 0.056\n",
      "EPOCH: 062: | train_loss: 0.018: | valid_loss: 0.057\n",
      "EPOCH: 063: | train_loss: 0.017: | valid_loss: 0.056\n",
      "EPOCH: 064: | train_loss: 0.016: | valid_loss: 0.056\n",
      "EPOCH: 065: | train_loss: 0.016: | valid_loss: 0.056\n",
      "EPOCH: 066: | train_loss: 0.015: | valid_loss: 0.055\n",
      "EPOCH: 067: | train_loss: 0.014: | valid_loss: 0.056\n",
      "EPOCH: 068: | train_loss: 0.013: | valid_loss: 0.056\n",
      "EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 070: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 071: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 072: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 073: | train_loss: 0.012: | valid_loss: 0.055\n",
      "EPOCH: 074: | train_loss: 0.012: | valid_loss: 0.056\n",
      "<BEST LOSS> EPOCH: 069: | train_loss: 0.012: | valid_loss: 0.055\n",
      "CV cross entropy:  0.05489628357002558\n",
      "CV accuracy:  0.90996\n",
      "CPU times: user 1h 15min 49s, sys: 7.86 s, total: 1h 15min 56s\n",
      "Wall time: 1h 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score, oof, predictions = Exec(param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.24481105e-07, 4.03229478e-07, 1.11192058e-07, 2.06106677e-07,\n",
       "       9.99999762e-01, 6.32354443e-07, 2.39535694e-07, 3.85809614e-07,\n",
       "       8.85900931e-07, 1.92100970e-06])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999997615814209"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof[3][np.argmax(oof[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(oof[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, targetVsl = preprocessing(param_space, trainFeature, testFeature, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTarget.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= np.zeros((trainTarget.shape[0],))\n",
    "for i in range(trainTarget.shape[0]):\n",
    "    y_pred[i] = np.argmax(oof[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 9., 9., ..., 9., 1., 1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(confFitting, param, test, target, fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "  \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test[confFitting[\"feature_cols\"]].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=confFitting[\"num_features\"],\n",
    "        num_targets=confFitting[\"num_targets\"],\n",
    "        param=param\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"{SAVEMODEL}SEED{seed}_FOLD{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        if Tester:\n",
    "            print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "        pred_ = run_predict(confFitting, param, test, target, fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPredict(confFitting, predictions, test, prefix):\n",
    "    test[confFitting[\"target_cols\"]] = predictions\n",
    "    sub = sample_submission.drop(columns=confFitting[\"target_cols\"]).merge(test[['sig_id']+confFitting[\"target_cols\"]], on='sig_id', how='left').fillna(0)\n",
    "    sub.to_csv(f'{SUBMIT}{prefix}submission.csv', index=False)\n",
    "\n",
    "    print(\"sub.shape\" + str(sub.shape))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        predictions_ = run_k_fold_predict(confFitting, test, target, param, Tester, NFOLDS, seed)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    # 課題提出\n",
    "    prefix = \"Pytorch\"\n",
    "    SubmitPredict(confFitting, predictions, test, prefix)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Predict(param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperopt\n",
    "from hyperopt import fmin, tpe, hp, rand, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOptExec(param):\n",
    "    #Tester(True/False)\n",
    "    Tester = False\n",
    "    \n",
    "    #Preprocessing Data\n",
    "    train, test, target = preprocessing(param, trainFeature, testFeature, trainTargetScored)\n",
    "    \n",
    "    #CV folds\n",
    "    folds = CV_folds(train, target)\n",
    "    \n",
    "    #Config about Fitting\n",
    "    confFitting = Config_about_Fitting(train, test, target, folds)\n",
    "    \n",
    "    # Averaging on multiple SEEDS\n",
    "    SEED = [0, 1, 2, 3 ,4, 5]\n",
    "    oof = np.zeros((len(train), confFitting[\"num_targets\"]))\n",
    "    predictions = np.zeros((len(test), confFitting[\"num_targets\"]))\n",
    "    \n",
    "    ### RUN ###\n",
    "    for seed in SEED:\n",
    "        if Tester:\n",
    "            print('~' * 20, 'SEED', seed, '~' * 20)\n",
    "        oof_, predictions_ = run_k_fold(Tester, NFOLDS, seed, param,\n",
    "                                       folds, train, test, target, confFitting)\n",
    "        oof += oof_ / len(SEED)\n",
    "        predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    #CV 評価\n",
    "    score = CV_Evaluation(confFitting, oof, train, target)\n",
    "    \n",
    "    # 課題提出\n",
    "    #Submit(confFitting, predictions, test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#param_space = {'hidden_size1': 512, \n",
    "#               'hidden_size2': 512, \n",
    "#               'dropOutRate1': 0.20393004966355735, \n",
    "#               'dropOutRate2': 0.39170486751620137,\n",
    "#               'rankGauss_n_quantiles': 488.0393350201078,\n",
    "#               'leakyReluSlope': hp.uniform('leakyReluSlope', 1e-3, 1e-1),\n",
    "#              }\n",
    "#\n",
    "#trials = Trials()\n",
    "#\n",
    "#hopt = fmin(fn = HOptExec, \n",
    "#            space = param_space, \n",
    "#            algo = tpe.suggest, \n",
    "#            max_evals = 15, \n",
    "#            #timeout = 8.9 * 60 * 60, \n",
    "#            trials = trials, \n",
    "#           )\n",
    "#\n",
    "#print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
